
	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 16000 --kpath /tmp/edgesCells_GADM_K_16000.wkt --qpath /tmp/edgesCells_GADM_Q_16000.wkt --master yarn
2024-03-04 18:12:21,897|13784|application_1709003950326_0703|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 16000 --kpath /tmp/edgesCells_GADM_K_16000.wkt --qpath /tmp/edgesCells_GADM_Q_16000.wkt --master yarn
2024-03-04 18:12:21,897|13784|application_1709003950326_0703|TIME|Start
2024-03-04 18:12:21,897|13784|application_1709003950326_0703|INFO|tag|scale|1000.0
2024-03-04 18:12:36,892|28779|application_1709003950326_0703|INFO|tag|edgesA|68779746
2024-03-04 18:12:50,534|42421|application_1709003950326_0703|INFO|tag|edgesB|64598411
2024-03-04 18:12:57,514|49401|application_1709003950326_0703|INFO|tag|TotalEdges|133378157
2024-03-04 18:13:06,557|58444|application_1709003950326_0703|INFO|tag|Requested_partitions|16000
2024-03-04 18:13:06,558|58445|application_1709003950326_0703|INFO|tag|Sample_size|1333781
2024-03-04 18:13:06,559|58446|application_1709003950326_0703|INFO|tag|Fraction|0.01003722781272588
2024-03-04 18:13:36,783|88670|application_1709003950326_0703|INFO|tag|Kdtree|maxItemsPerCell|83
2024-03-04 18:13:39,729|91616|application_1709003950326_0703|TIME|tag|16000|Kdtree|creation|33.168241182
2024-03-04 18:13:39,729|91616|application_1709003950326_0703|INFO|tag|16000|Kdtree|space|23119
2024-03-04 18:17:19,688|311575|application_1709003950326_0703|INFO|tag|Kdtree|16000|nEdgesA|69136431
2024-03-04 18:17:19,688|311575|application_1709003950326_0703|INFO|tag|Kdtree|16000|nEdgesB|64887863
2024-03-04 18:17:19,689|311576|application_1709003950326_0703|TIME|tag|16000|Kdtree|partitioning|219.370939266
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 2090 in stage 13.0 failed 4 times, most recent failure: Lost task 2090.3 in stage 13.0 (TID 49765, mr-04, executor 6): java.lang.NullPointerException

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.DCELOverlay2$.overlay(DCELOverlay2.scala:34)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:132)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.Utils$.timer(Utils.scala:162)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$.main(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner.main(SDCEL_Partitioner.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.NullPointerException

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 17000 --kpath /tmp/edgesCells_GADM_K_17000.wkt --qpath /tmp/edgesCells_GADM_Q_17000.wkt --master yarn
2024-03-04 18:18:18,998|13825|application_1709003950326_0704|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 17000 --kpath /tmp/edgesCells_GADM_K_17000.wkt --qpath /tmp/edgesCells_GADM_Q_17000.wkt --master yarn
2024-03-04 18:18:18,999|13826|application_1709003950326_0704|TIME|Start
2024-03-04 18:18:18,999|13826|application_1709003950326_0704|INFO|tag|scale|1000.0
2024-03-04 18:18:53,577|48404|application_1709003950326_0704|INFO|tag|edgesA|68779746
2024-03-04 18:19:06,336|61163|application_1709003950326_0704|INFO|tag|edgesB|64598411
2024-03-04 18:19:13,910|68737|application_1709003950326_0704|INFO|tag|TotalEdges|133378157
2024-03-04 18:19:15,057|69884|application_1709003950326_0704|INFO|tag|Requested_partitions|17000
2024-03-04 18:19:15,058|69885|application_1709003950326_0704|INFO|tag|Sample_size|1333781
2024-03-04 18:19:15,059|69886|application_1709003950326_0704|INFO|tag|Fraction|0.01003722781272588
2024-03-04 18:19:42,276|97103|application_1709003950326_0704|INFO|tag|Kdtree|maxItemsPerCell|78
2024-03-04 18:19:45,876|100703|application_1709003950326_0704|TIME|tag|17000|Kdtree|creation|30.814843353
2024-03-04 18:19:45,876|100703|application_1709003950326_0704|INFO|tag|17000|Kdtree|space|24615
2024-03-04 18:23:22,698|317525|application_1709003950326_0704|INFO|tag|Kdtree|17000|nEdgesA|69147051
2024-03-04 18:23:22,698|317525|application_1709003950326_0704|INFO|tag|Kdtree|17000|nEdgesB|64895400
2024-03-04 18:23:22,699|317526|application_1709003950326_0704|TIME|tag|17000|Kdtree|partitioning|216.819114926
2024-03-04 18:28:54,653|649480|application_1709003950326_0704|INFO|tag|Kdtree|17000|nOverlay|300438
2024-03-04 18:28:54,653|649480|application_1709003950326_0704|TIME|tag|17000|Kdtree|overlay|331.949817624
2024-03-04 18:28:55,413|650240|Saved /tmp/edgesCells_GADM_K_17000.wkt in 0.07s [24615 records].
2024-03-04 18:28:56,459|651286|application_1709003950326_0704|INFO|tag|Quadtree|17000|maxItemsPerCell|78
2024-03-04 18:29:04,518|659345|application_1709003950326_0704|TIME|tag|17000|Quadtree|creation|9.102876932
2024-03-04 18:29:04,519|659346|application_1709003950326_0704|INFO|tag|17000|Quadtree|space|46108
2024-03-04 18:35:05,839|1020666|application_1709003950326_0704|INFO|tag|Quadtree|17000|nEdgesA|69096110
2024-03-04 18:35:05,840|1020667|application_1709003950326_0704|INFO|tag|Quadtree|17000|nEdgesB|64833918
2024-03-04 18:35:05,840|1020667|application_1709003950326_0704|TIME|tag|17000|Quadtree|partitioning|361.317023366
2024-03-04 18:42:07,208|1442035|application_1709003950326_0704|INFO|tag|Quadtree|17000|nOverlay|306256
2024-03-04 18:42:07,208|1442035|application_1709003950326_0704|TIME|tag|17000|Quadtree|overlay|421.360873214
2024-03-04 18:42:08,221|1443048|Saved /tmp/edgesCells_GADM_Q_17000.wkt in 0.08s [46108 records].
2024-03-04 18:42:08,403|1443230|application_1709003950326_0704|TIME|End

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 18000 --kpath /tmp/edgesCells_GADM_K_18000.wkt --qpath /tmp/edgesCells_GADM_Q_18000.wkt --master yarn
2024-03-04 18:42:29,353|14237|application_1709003950326_0705|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 18000 --kpath /tmp/edgesCells_GADM_K_18000.wkt --qpath /tmp/edgesCells_GADM_Q_18000.wkt --master yarn
2024-03-04 18:42:29,353|14237|application_1709003950326_0705|TIME|Start
2024-03-04 18:42:29,354|14238|application_1709003950326_0705|INFO|tag|scale|1000.0
2024-03-04 18:42:45,837|30721|application_1709003950326_0705|INFO|tag|edgesA|68779746
2024-03-04 18:42:57,635|42519|application_1709003950326_0705|INFO|tag|edgesB|64598411
2024-03-04 18:43:04,539|49423|application_1709003950326_0705|INFO|tag|TotalEdges|133378157
2024-03-04 18:43:24,793|69677|application_1709003950326_0705|INFO|tag|Requested_partitions|18000
2024-03-04 18:43:24,794|69678|application_1709003950326_0705|INFO|tag|Sample_size|1333781
2024-03-04 18:43:24,795|69679|application_1709003950326_0705|INFO|tag|Fraction|0.01003722781272588
2024-03-04 18:43:58,912|103796|application_1709003950326_0705|INFO|tag|Kdtree|maxItemsPerCell|74
2024-03-04 18:44:01,901|106785|application_1709003950326_0705|TIME|tag|18000|Kdtree|creation|37.104152232
2024-03-04 18:44:01,902|106786|application_1709003950326_0705|INFO|tag|18000|Kdtree|space|26062
2024-03-04 18:48:11,744|356628|application_1709003950326_0705|INFO|tag|Kdtree|18000|nEdgesA|69169479
2024-03-04 18:48:11,744|356628|application_1709003950326_0705|INFO|tag|Kdtree|18000|nEdgesB|64913027
2024-03-04 18:48:11,745|356629|application_1709003950326_0705|TIME|tag|18000|Kdtree|partitioning|249.84073142
2024-03-04 18:53:33,550|678434|application_1709003950326_0705|INFO|tag|Kdtree|18000|nOverlay|301233
2024-03-04 18:53:33,550|678434|application_1709003950326_0705|TIME|tag|18000|Kdtree|overlay|321.800247626
2024-03-04 18:53:34,292|679176|Saved /tmp/edgesCells_GADM_K_18000.wkt in 0.04s [26062 records].
2024-03-04 18:53:35,277|680161|application_1709003950326_0705|INFO|tag|Quadtree|18000|maxItemsPerCell|74
2024-03-04 18:53:42,084|686968|application_1709003950326_0705|TIME|tag|18000|Quadtree|creation|7.790614316
2024-03-04 18:53:42,084|686968|application_1709003950326_0705|INFO|tag|18000|Quadtree|space|48754
2024-03-04 19:00:08,751|1073635|application_1709003950326_0705|INFO|tag|Quadtree|18000|nEdgesA|69105579
2024-03-04 19:00:08,751|1073635|application_1709003950326_0705|INFO|tag|Quadtree|18000|nEdgesB|64841390
2024-03-04 19:00:08,751|1073635|application_1709003950326_0705|TIME|tag|18000|Quadtree|partitioning|386.665502328
2024-03-04 19:07:13,298|1498182|application_1709003950326_0705|INFO|tag|Quadtree|18000|nOverlay|307256
2024-03-04 19:07:13,298|1498182|application_1709003950326_0705|TIME|tag|18000|Quadtree|overlay|424.542419994
2024-03-04 19:07:14,381|1499265|Saved /tmp/edgesCells_GADM_Q_18000.wkt in 0.08s [48754 records].
2024-03-04 19:07:14,556|1499440|application_1709003950326_0705|TIME|End

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 19000 --kpath /tmp/edgesCells_GADM_K_19000.wkt --qpath /tmp/edgesCells_GADM_Q_19000.wkt --master yarn
2024-03-04 19:07:34,940|13820|application_1709003950326_0706|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 19000 --kpath /tmp/edgesCells_GADM_K_19000.wkt --qpath /tmp/edgesCells_GADM_Q_19000.wkt --master yarn
2024-03-04 19:07:34,944|13824|application_1709003950326_0706|TIME|Start
2024-03-04 19:07:34,945|13825|application_1709003950326_0706|INFO|tag|scale|1000.0
2024-03-04 19:07:50,582|29462|application_1709003950326_0706|INFO|tag|edgesA|68779746
2024-03-04 19:07:59,991|38871|application_1709003950326_0706|INFO|tag|edgesB|64598411
2024-03-04 19:08:02,486|41366|application_1709003950326_0706|INFO|tag|TotalEdges|133378157
2024-03-04 19:08:11,371|50251|application_1709003950326_0706|INFO|tag|Requested_partitions|19000
2024-03-04 19:08:11,372|50252|application_1709003950326_0706|INFO|tag|Sample_size|1333781
2024-03-04 19:08:11,373|50253|application_1709003950326_0706|INFO|tag|Fraction|0.01003722781272588
2024-03-04 19:09:05,099|103979|application_1709003950326_0706|INFO|tag|Kdtree|maxItemsPerCell|70
2024-03-04 19:09:07,976|106856|application_1709003950326_0706|TIME|tag|19000|Kdtree|creation|56.600862152
2024-03-04 19:09:07,976|106856|application_1709003950326_0706|INFO|tag|19000|Kdtree|space|27590
2024-03-04 19:13:08,978|347858|application_1709003950326_0706|INFO|tag|Kdtree|19000|nEdgesA|69176193
2024-03-04 19:13:08,979|347859|application_1709003950326_0706|INFO|tag|Kdtree|19000|nEdgesB|64917651
2024-03-04 19:13:08,979|347859|application_1709003950326_0706|TIME|tag|19000|Kdtree|partitioning|241.001269001
2024-03-04 19:19:05,752|704632|application_1709003950326_0706|INFO|tag|Kdtree|19000|nOverlay|301697
2024-03-04 19:19:05,752|704632|application_1709003950326_0706|TIME|tag|19000|Kdtree|overlay|357.141458448
2024-03-04 19:19:06,464|705344|Saved /tmp/edgesCells_GADM_K_19000.wkt in 0.04s [27590 records].
2024-03-04 19:19:07,400|706280|application_1709003950326_0706|INFO|tag|Quadtree|19000|maxItemsPerCell|70
2024-03-04 19:19:13,571|712451|application_1709003950326_0706|TIME|tag|19000|Quadtree|creation|7.103413199
2024-03-04 19:19:13,572|712452|application_1709003950326_0706|INFO|tag|19000|Quadtree|space|51766
2024-03-04 19:26:45,118|1163998|application_1709003950326_0706|INFO|tag|Quadtree|19000|nEdgesA|69116962
2024-03-04 19:26:45,118|1163998|application_1709003950326_0706|INFO|tag|Quadtree|19000|nEdgesB|64850369
2024-03-04 19:26:45,118|1163998|application_1709003950326_0706|TIME|tag|19000|Quadtree|partitioning|451.543744803
2024-03-04 19:34:12,738|1611618|application_1709003950326_0706|INFO|tag|Quadtree|19000|nOverlay|308236
2024-03-04 19:34:12,738|1611618|application_1709003950326_0706|TIME|tag|19000|Quadtree|overlay|447.615599427
2024-03-04 19:34:13,829|1612709|Saved /tmp/edgesCells_GADM_Q_19000.wkt in 0.08s [51766 records].
2024-03-04 19:34:14,009|1612889|application_1709003950326_0706|TIME|End

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 20000 --kpath /tmp/edgesCells_GADM_K_20000.wkt --qpath /tmp/edgesCells_GADM_Q_20000.wkt --master yarn
2024-03-04 19:34:34,145|13999|application_1709003950326_0707|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 20000 --kpath /tmp/edgesCells_GADM_K_20000.wkt --qpath /tmp/edgesCells_GADM_Q_20000.wkt --master yarn
2024-03-04 19:34:34,146|14000|application_1709003950326_0707|TIME|Start
2024-03-04 19:34:34,146|14000|application_1709003950326_0707|INFO|tag|scale|1000.0
2024-03-04 19:34:49,845|29699|application_1709003950326_0707|INFO|tag|edgesA|68779746
2024-03-04 19:35:26,768|66622|application_1709003950326_0707|INFO|tag|edgesB|64598411
2024-03-04 19:35:29,053|68907|application_1709003950326_0707|INFO|tag|TotalEdges|133378157
2024-03-04 19:35:36,936|76790|application_1709003950326_0707|INFO|tag|Requested_partitions|20000
2024-03-04 19:35:36,937|76791|application_1709003950326_0707|INFO|tag|Sample_size|1333781
2024-03-04 19:35:36,938|76792|application_1709003950326_0707|INFO|tag|Fraction|0.01003722781272588
2024-03-04 19:36:01,707|101561|application_1709003950326_0707|INFO|tag|Kdtree|maxItemsPerCell|66
2024-03-04 19:36:04,392|104246|application_1709003950326_0707|TIME|tag|20000|Kdtree|creation|27.452185904
2024-03-04 19:36:04,392|104246|application_1709003950326_0707|INFO|tag|20000|Kdtree|space|29228
2024-03-04 19:40:24,627|364481|application_1709003950326_0707|INFO|tag|Kdtree|20000|nEdgesA|69193140
2024-03-04 19:40:24,627|364481|application_1709003950326_0707|INFO|tag|Kdtree|20000|nEdgesB|64935364
2024-03-04 19:40:24,627|364481|application_1709003950326_0707|TIME|tag|20000|Kdtree|partitioning|260.233110536
2024-03-04 19:46:22,123|721977|application_1709003950326_0707|INFO|tag|Kdtree|20000|nOverlay|301891
2024-03-04 19:46:22,123|721977|application_1709003950326_0707|TIME|tag|20000|Kdtree|overlay|357.491873638
2024-03-04 19:46:22,886|722740|Saved /tmp/edgesCells_GADM_K_20000.wkt in 0.04s [29228 records].
2024-03-04 19:46:23,665|723519|application_1709003950326_0707|INFO|tag|Quadtree|20000|maxItemsPerCell|66
2024-03-04 19:46:31,265|731119|application_1709003950326_0707|TIME|tag|20000|Quadtree|creation|8.376609784
2024-03-04 19:46:31,265|731119|application_1709003950326_0707|INFO|tag|20000|Quadtree|space|55096
2024-03-04 19:54:19,922|1199776|application_1709003950326_0707|INFO|tag|Quadtree|20000|nEdgesA|69129591
2024-03-04 19:54:19,923|1199777|application_1709003950326_0707|INFO|tag|Quadtree|20000|nEdgesB|64859892
2024-03-04 19:54:19,923|1199777|application_1709003950326_0707|TIME|tag|20000|Quadtree|partitioning|468.655835842
2024-03-04 20:02:12,327|1672181|application_1709003950326_0707|INFO|tag|Quadtree|20000|nOverlay|309402
2024-03-04 20:02:12,327|1672181|application_1709003950326_0707|TIME|tag|20000|Quadtree|overlay|472.40064037
2024-03-04 20:02:13,597|1673451|Saved /tmp/edgesCells_GADM_Q_20000.wkt in 0.09s [55096 records].
2024-03-04 20:02:13,779|1673633|application_1709003950326_0707|TIME|End

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 21000 --kpath /tmp/edgesCells_GADM_K_21000.wkt --qpath /tmp/edgesCells_GADM_Q_21000.wkt --master yarn
2024-03-04 20:02:35,048|14303|application_1709003950326_0708|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 21000 --kpath /tmp/edgesCells_GADM_K_21000.wkt --qpath /tmp/edgesCells_GADM_Q_21000.wkt --master yarn
2024-03-04 20:02:35,048|14303|application_1709003950326_0708|TIME|Start
2024-03-04 20:02:35,049|14304|application_1709003950326_0708|INFO|tag|scale|1000.0
2024-03-04 20:03:32,751|72006|application_1709003950326_0708|INFO|tag|edgesA|68779746
2024-03-04 20:03:43,627|82882|application_1709003950326_0708|INFO|tag|edgesB|64598411
2024-03-04 20:03:48,855|88110|application_1709003950326_0708|INFO|tag|TotalEdges|133378157
2024-03-04 20:03:49,795|89050|application_1709003950326_0708|INFO|tag|Requested_partitions|21000
2024-03-04 20:03:49,796|89051|application_1709003950326_0708|INFO|tag|Sample_size|1333781
2024-03-04 20:03:49,797|89052|application_1709003950326_0708|INFO|tag|Fraction|0.01003722781272588
2024-03-04 20:04:11,379|110634|application_1709003950326_0708|INFO|tag|Kdtree|maxItemsPerCell|63
2024-03-04 20:04:15,163|114418|application_1709003950326_0708|TIME|tag|21000|Kdtree|creation|25.364584565
2024-03-04 20:04:15,164|114419|application_1709003950326_0708|INFO|tag|21000|Kdtree|space|30558
2024-03-04 20:08:14,798|354053|application_1709003950326_0708|INFO|tag|Kdtree|21000|nEdgesA|69214143
2024-03-04 20:08:14,798|354053|application_1709003950326_0708|INFO|tag|Kdtree|21000|nEdgesB|64949515
2024-03-04 20:08:14,798|354053|application_1709003950326_0708|TIME|tag|21000|Kdtree|partitioning|239.624663121
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 6628 in stage 13.0 failed 4 times, most recent failure: Lost task 6628.3 in stage 13.0 (TID 69097, mr-11, executor 6): java.lang.NullPointerException

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.DCELOverlay2$.overlay(DCELOverlay2.scala:34)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:132)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.Utils$.timer(Utils.scala:162)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$.main(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner.main(SDCEL_Partitioner.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.NullPointerException

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 22000 --kpath /tmp/edgesCells_GADM_K_22000.wkt --qpath /tmp/edgesCells_GADM_Q_22000.wkt --master yarn
2024-03-04 20:09:39,645|14245|application_1709003950326_0709|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 22000 --kpath /tmp/edgesCells_GADM_K_22000.wkt --qpath /tmp/edgesCells_GADM_Q_22000.wkt --master yarn
2024-03-04 20:09:39,646|14246|application_1709003950326_0709|TIME|Start
2024-03-04 20:09:39,646|14246|application_1709003950326_0709|INFO|tag|scale|1000.0
2024-03-04 20:09:54,965|29565|application_1709003950326_0709|INFO|tag|edgesA|68779746
2024-03-04 20:10:06,248|40848|application_1709003950326_0709|INFO|tag|edgesB|64598411
2024-03-04 20:10:08,353|42953|application_1709003950326_0709|INFO|tag|TotalEdges|133378157
2024-03-04 20:10:14,814|49414|application_1709003950326_0709|INFO|tag|Requested_partitions|22000
2024-03-04 20:10:14,816|49416|application_1709003950326_0709|INFO|tag|Sample_size|1333781
2024-03-04 20:10:14,817|49417|application_1709003950326_0709|INFO|tag|Fraction|0.01003722781272588
2024-03-04 20:10:56,030|90630|application_1709003950326_0709|INFO|tag|Kdtree|maxItemsPerCell|60
2024-03-04 20:10:59,335|93935|application_1709003950326_0709|TIME|tag|22000|Kdtree|creation|44.515487373
2024-03-04 20:10:59,335|93935|application_1709003950326_0709|INFO|tag|22000|Kdtree|space|32026
2024-03-04 20:15:17,514|352114|application_1709003950326_0709|INFO|tag|Kdtree|22000|nEdgesA|69215379
2024-03-04 20:15:17,515|352115|application_1709003950326_0709|INFO|tag|Kdtree|22000|nEdgesB|64953655
2024-03-04 20:15:17,515|352115|application_1709003950326_0709|TIME|tag|22000|Kdtree|partitioning|258.176573492
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 9118 in stage 13.0 failed 4 times, most recent failure: Lost task 9118.3 in stage 13.0 (TID 74338, mr-01, executor 5): java.lang.NullPointerException

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.DCELOverlay2$.overlay(DCELOverlay2.scala:34)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:132)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.Utils$.timer(Utils.scala:162)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$.main(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner.main(SDCEL_Partitioner.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.NullPointerException

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 16000 --kpath /tmp/edgesCells_GADM_K_16000.wkt --qpath /tmp/edgesCells_GADM_Q_16000.wkt --master yarn
2024-03-04 20:17:00,036|13942|application_1709003950326_0710|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 16000 --kpath /tmp/edgesCells_GADM_K_16000.wkt --qpath /tmp/edgesCells_GADM_Q_16000.wkt --master yarn
2024-03-04 20:17:00,036|13942|application_1709003950326_0710|TIME|Start
2024-03-04 20:17:00,037|13943|application_1709003950326_0710|INFO|tag|scale|1000.0
2024-03-04 20:17:15,568|29474|application_1709003950326_0710|INFO|tag|edgesA|68779746
2024-03-04 20:17:26,791|40697|application_1709003950326_0710|INFO|tag|edgesB|64598411
2024-03-04 20:17:33,224|47130|application_1709003950326_0710|INFO|tag|TotalEdges|133378157
2024-03-04 20:17:41,554|55460|application_1709003950326_0710|INFO|tag|Requested_partitions|16000
2024-03-04 20:17:41,557|55463|application_1709003950326_0710|INFO|tag|Sample_size|1333781
2024-03-04 20:17:41,559|55465|application_1709003950326_0710|INFO|tag|Fraction|0.01003722781272588
2024-03-04 20:18:12,852|86758|application_1709003950326_0710|INFO|tag|Kdtree|maxItemsPerCell|83
2024-03-04 20:18:16,177|90083|application_1709003950326_0710|TIME|tag|16000|Kdtree|creation|34.612517205
2024-03-04 20:18:16,178|90084|application_1709003950326_0710|INFO|tag|16000|Kdtree|space|23187
2024-03-04 20:21:57,081|310987|application_1709003950326_0710|INFO|tag|Kdtree|16000|nEdgesA|69134685
2024-03-04 20:21:57,081|310987|application_1709003950326_0710|INFO|tag|Kdtree|16000|nEdgesB|64886476
2024-03-04 20:21:57,081|310987|application_1709003950326_0710|TIME|tag|16000|Kdtree|partitioning|220.901368063
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 22967 in stage 13.0 failed 4 times, most recent failure: Lost task 22967.3 in stage 13.0 (TID 71040, mr-07, executor 1): java.lang.NullPointerException

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.DCELOverlay2$.overlay(DCELOverlay2.scala:34)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:132)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.Utils$.timer(Utils.scala:162)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$.main(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner.main(SDCEL_Partitioner.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.NullPointerException

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 17000 --kpath /tmp/edgesCells_GADM_K_17000.wkt --qpath /tmp/edgesCells_GADM_Q_17000.wkt --master yarn
2024-03-04 20:26:54,182|14005|application_1709003950326_0711|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 17000 --kpath /tmp/edgesCells_GADM_K_17000.wkt --qpath /tmp/edgesCells_GADM_Q_17000.wkt --master yarn
2024-03-04 20:26:54,182|14005|application_1709003950326_0711|TIME|Start
2024-03-04 20:26:54,182|14005|application_1709003950326_0711|INFO|tag|scale|1000.0
2024-03-04 20:27:09,414|29237|application_1709003950326_0711|INFO|tag|edgesA|68779746
2024-03-04 20:27:20,652|40475|application_1709003950326_0711|INFO|tag|edgesB|64598411
2024-03-04 20:27:24,891|44714|application_1709003950326_0711|INFO|tag|TotalEdges|133378157
2024-03-04 20:27:36,136|55959|application_1709003950326_0711|INFO|tag|Requested_partitions|17000
2024-03-04 20:27:36,137|55960|application_1709003950326_0711|INFO|tag|Sample_size|1333781
2024-03-04 20:27:36,138|55961|application_1709003950326_0711|INFO|tag|Fraction|0.01003722781272588
2024-03-04 20:27:56,802|76625|application_1709003950326_0711|INFO|tag|Kdtree|maxItemsPerCell|78
2024-03-04 20:27:59,365|79188|application_1709003950326_0711|TIME|tag|17000|Kdtree|creation|23.225483124
2024-03-04 20:27:59,366|79189|application_1709003950326_0711|INFO|tag|17000|Kdtree|space|24693
2024-03-04 20:31:47,124|306947|application_1709003950326_0711|INFO|tag|Kdtree|17000|nEdgesA|69149819
2024-03-04 20:31:47,124|306947|application_1709003950326_0711|INFO|tag|Kdtree|17000|nEdgesB|64895047
2024-03-04 20:31:47,125|306948|application_1709003950326_0711|TIME|tag|17000|Kdtree|partitioning|227.757011585
2024-03-04 20:37:19,873|639696|application_1709003950326_0711|INFO|tag|Kdtree|17000|nOverlay|300590
2024-03-04 20:37:19,873|639696|application_1709003950326_0711|TIME|tag|17000|Kdtree|overlay|332.745368284
2024-03-04 20:37:20,489|640312|Saved /tmp/edgesCells_GADM_K_17000.wkt in 0.04s [24693 records].
2024-03-04 20:37:21,266|641089|application_1709003950326_0711|INFO|tag|Quadtree|17000|maxItemsPerCell|78
2024-03-04 20:37:26,798|646621|application_1709003950326_0711|TIME|tag|17000|Quadtree|creation|6.307012956
2024-03-04 20:37:26,799|646622|application_1709003950326_0711|INFO|tag|17000|Quadtree|space|46108
2024-03-04 20:43:46,839|1026662|application_1709003950326_0711|INFO|tag|Quadtree|17000|nEdgesA|69096110
2024-03-04 20:43:46,840|1026663|application_1709003950326_0711|INFO|tag|Quadtree|17000|nEdgesB|64833918
2024-03-04 20:43:46,840|1026663|application_1709003950326_0711|TIME|tag|17000|Quadtree|partitioning|380.038870605
2024-03-04 20:50:37,911|1437734|application_1709003950326_0711|INFO|tag|Quadtree|17000|nOverlay|306201
2024-03-04 20:50:37,911|1437734|application_1709003950326_0711|TIME|tag|17000|Quadtree|overlay|411.066107102
2024-03-04 20:50:39,153|1438976|Saved /tmp/edgesCells_GADM_Q_17000.wkt in 0.08s [46108 records].
2024-03-04 20:50:39,478|1439301|application_1709003950326_0711|TIME|End

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 18000 --kpath /tmp/edgesCells_GADM_K_18000.wkt --qpath /tmp/edgesCells_GADM_Q_18000.wkt --master yarn
2024-03-04 20:51:00,962|14202|application_1709003950326_0712|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 18000 --kpath /tmp/edgesCells_GADM_K_18000.wkt --qpath /tmp/edgesCells_GADM_Q_18000.wkt --master yarn
2024-03-04 20:51:00,963|14203|application_1709003950326_0712|TIME|Start
2024-03-04 20:51:00,963|14203|application_1709003950326_0712|INFO|tag|scale|1000.0
2024-03-04 20:51:16,154|29394|application_1709003950326_0712|INFO|tag|edgesA|68779746
2024-03-04 20:51:26,545|39785|application_1709003950326_0712|INFO|tag|edgesB|64598411
2024-03-04 20:51:28,289|41529|application_1709003950326_0712|INFO|tag|TotalEdges|133378157
2024-03-04 20:51:36,972|50212|application_1709003950326_0712|INFO|tag|Requested_partitions|18000
2024-03-04 20:51:36,975|50215|application_1709003950326_0712|INFO|tag|Sample_size|1333781
2024-03-04 20:51:36,977|50217|application_1709003950326_0712|INFO|tag|Fraction|0.01003722781272588
2024-03-04 20:52:17,574|90814|application_1709003950326_0712|INFO|tag|Kdtree|maxItemsPerCell|74
2024-03-04 20:52:20,823|94063|application_1709003950326_0712|TIME|tag|18000|Kdtree|creation|43.843744839
2024-03-04 20:52:20,824|94064|application_1709003950326_0712|INFO|tag|18000|Kdtree|space|26040
2024-03-04 20:56:08,248|321488|application_1709003950326_0712|INFO|tag|Kdtree|18000|nEdgesA|69169860
2024-03-04 20:56:08,249|321489|application_1709003950326_0712|INFO|tag|Kdtree|18000|nEdgesB|64913562
2024-03-04 20:56:08,249|321489|application_1709003950326_0712|TIME|tag|18000|Kdtree|partitioning|227.42086922
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 17747 in stage 13.0 failed 4 times, most recent failure: Lost task 17747.3 in stage 13.0 (TID 71619, mr-03, executor 12): java.lang.NullPointerException
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$10.apply(LocalDCEL.scala:71)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$10.apply(LocalDCEL.scala:71)
	at scala.collection.TraversableLike$$anonfun$filterImpl$1.apply(TraversableLike.scala:248)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at scala.collection.TraversableLike$class.filterImpl(TraversableLike.scala:247)
	at scala.collection.TraversableLike$class.filter(TraversableLike.scala:259)
	at scala.collection.AbstractTraversable.filter(Traversable.scala:104)
	at edu.ucr.dblab.sdcel.LocalDCEL$.merge(LocalDCEL.scala:71)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$1.apply(LocalDCEL.scala:56)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$1.apply(LocalDCEL.scala:19)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.DCELOverlay2$.overlay(DCELOverlay2.scala:34)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:132)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.Utils$.timer(Utils.scala:162)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$.main(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner.main(SDCEL_Partitioner.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.NullPointerException
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$10.apply(LocalDCEL.scala:71)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$10.apply(LocalDCEL.scala:71)
	at scala.collection.TraversableLike$$anonfun$filterImpl$1.apply(TraversableLike.scala:248)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at scala.collection.TraversableLike$class.filterImpl(TraversableLike.scala:247)
	at scala.collection.TraversableLike$class.filter(TraversableLike.scala:259)
	at scala.collection.AbstractTraversable.filter(Traversable.scala:104)
	at edu.ucr.dblab.sdcel.LocalDCEL$.merge(LocalDCEL.scala:71)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$1.apply(LocalDCEL.scala:56)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$1.apply(LocalDCEL.scala:19)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 19000 --kpath /tmp/edgesCells_GADM_K_19000.wkt --qpath /tmp/edgesCells_GADM_Q_19000.wkt --master yarn
2024-03-04 20:59:46,867|13700|application_1709003950326_0713|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 19000 --kpath /tmp/edgesCells_GADM_K_19000.wkt --qpath /tmp/edgesCells_GADM_Q_19000.wkt --master yarn
2024-03-04 20:59:46,867|13700|application_1709003950326_0713|TIME|Start
2024-03-04 20:59:46,868|13701|application_1709003950326_0713|INFO|tag|scale|1000.0
2024-03-04 21:00:02,227|29060|application_1709003950326_0713|INFO|tag|edgesA|68779746
2024-03-04 21:00:12,441|39274|application_1709003950326_0713|INFO|tag|edgesB|64598411
2024-03-04 21:00:18,813|45646|application_1709003950326_0713|INFO|tag|TotalEdges|133378157
2024-03-04 21:00:40,934|67767|application_1709003950326_0713|INFO|tag|Requested_partitions|19000
2024-03-04 21:00:40,935|67768|application_1709003950326_0713|INFO|tag|Sample_size|1333781
2024-03-04 21:00:40,936|67769|application_1709003950326_0713|INFO|tag|Fraction|0.01003722781272588
2024-03-04 21:01:07,443|94276|application_1709003950326_0713|INFO|tag|Kdtree|maxItemsPerCell|70
2024-03-04 21:01:10,368|97201|application_1709003950326_0713|TIME|tag|19000|Kdtree|creation|29.429926077
2024-03-04 21:01:10,369|97202|application_1709003950326_0713|INFO|tag|19000|Kdtree|space|27484
2024-03-04 21:04:47,687|314520|application_1709003950326_0713|INFO|tag|Kdtree|19000|nEdgesA|69179620
2024-03-04 21:04:47,687|314520|application_1709003950326_0713|INFO|tag|Kdtree|19000|nEdgesB|64920389
2024-03-04 21:04:47,688|314521|application_1709003950326_0713|TIME|tag|19000|Kdtree|partitioning|217.317438596
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 20044 in stage 13.0 failed 4 times, most recent failure: Lost task 20044.3 in stage 13.0 (TID 76158, mr-11, executor 12): java.lang.NullPointerException

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.DCELOverlay2$.overlay(DCELOverlay2.scala:34)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:132)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.Utils$.timer(Utils.scala:162)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$.main(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner.main(SDCEL_Partitioner.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.NullPointerException

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 20000 --kpath /tmp/edgesCells_GADM_K_20000.wkt --qpath /tmp/edgesCells_GADM_Q_20000.wkt --master yarn
2024-03-04 21:08:28,503|13668|application_1709003950326_0714|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 20000 --kpath /tmp/edgesCells_GADM_K_20000.wkt --qpath /tmp/edgesCells_GADM_Q_20000.wkt --master yarn
2024-03-04 21:08:28,504|13669|application_1709003950326_0714|TIME|Start
2024-03-04 21:08:28,504|13669|application_1709003950326_0714|INFO|tag|scale|1000.0
2024-03-04 21:08:45,294|30459|application_1709003950326_0714|INFO|tag|edgesA|68779746
2024-03-04 21:08:57,760|42925|application_1709003950326_0714|INFO|tag|edgesB|64598411
2024-03-04 21:09:04,314|49479|application_1709003950326_0714|INFO|tag|TotalEdges|133378157
2024-03-04 21:09:12,337|57502|application_1709003950326_0714|INFO|tag|Requested_partitions|20000
2024-03-04 21:09:12,339|57504|application_1709003950326_0714|INFO|tag|Sample_size|1333781
2024-03-04 21:09:12,340|57505|application_1709003950326_0714|INFO|tag|Fraction|0.01003722781272588
2024-03-04 21:09:37,968|83133|application_1709003950326_0714|INFO|tag|Kdtree|maxItemsPerCell|66
2024-03-04 21:09:41,335|86500|application_1709003950326_0714|TIME|tag|20000|Kdtree|creation|28.992929059
2024-03-04 21:09:41,337|86502|application_1709003950326_0714|INFO|tag|20000|Kdtree|space|29104
2024-03-04 21:13:23,764|308929|application_1709003950326_0714|INFO|tag|Kdtree|20000|nEdgesA|69193962
2024-03-04 21:13:23,764|308929|application_1709003950326_0714|INFO|tag|Kdtree|20000|nEdgesB|64932064
2024-03-04 21:13:23,764|308929|application_1709003950326_0714|TIME|tag|20000|Kdtree|partitioning|222.423889583
2024-03-04 21:19:07,388|652553|application_1709003950326_0714|INFO|tag|Kdtree|20000|nOverlay|302222
2024-03-04 21:19:07,388|652553|application_1709003950326_0714|TIME|tag|20000|Kdtree|overlay|343.865685503
2024-03-04 21:19:08,233|653398|Saved /tmp/edgesCells_GADM_K_20000.wkt in 0.04s [29104 records].
2024-03-04 21:19:09,185|654350|application_1709003950326_0714|INFO|tag|Quadtree|20000|maxItemsPerCell|66
2024-03-04 21:19:16,054|661219|application_1709003950326_0714|TIME|tag|20000|Quadtree|creation|7.820001197
2024-03-04 21:19:16,055|661220|application_1709003950326_0714|INFO|tag|20000|Quadtree|space|55096
2024-03-04 21:26:58,985|1124150|application_1709003950326_0714|INFO|tag|Quadtree|20000|nEdgesA|69129591
2024-03-04 21:26:58,985|1124150|application_1709003950326_0714|INFO|tag|Quadtree|20000|nEdgesB|64859892
2024-03-04 21:26:58,986|1124151|application_1709003950326_0714|TIME|tag|20000|Quadtree|partitioning|462.927488298
2024-03-04 21:34:57,078|1602243|application_1709003950326_0714|INFO|tag|Quadtree|20000|nOverlay|309415
2024-03-04 21:34:57,078|1602243|application_1709003950326_0714|TIME|tag|20000|Quadtree|overlay|478.088279537
2024-03-04 21:34:58,255|1603420|Saved /tmp/edgesCells_GADM_Q_20000.wkt in 0.09s [55096 records].
2024-03-04 21:34:58,442|1603607|application_1709003950326_0714|TIME|End

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 21000 --kpath /tmp/edgesCells_GADM_K_21000.wkt --qpath /tmp/edgesCells_GADM_Q_21000.wkt --master yarn
2024-03-04 21:35:19,075|14064|application_1709003950326_0715|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 21000 --kpath /tmp/edgesCells_GADM_K_21000.wkt --qpath /tmp/edgesCells_GADM_Q_21000.wkt --master yarn
2024-03-04 21:35:19,076|14065|application_1709003950326_0715|TIME|Start
2024-03-04 21:35:19,076|14065|application_1709003950326_0715|INFO|tag|scale|1000.0
2024-03-04 21:35:33,875|28864|application_1709003950326_0715|INFO|tag|edgesA|68779746
2024-03-04 21:35:43,483|38472|application_1709003950326_0715|INFO|tag|edgesB|64598411
2024-03-04 21:35:50,234|45223|application_1709003950326_0715|INFO|tag|TotalEdges|133378157
2024-03-04 21:35:59,272|54261|application_1709003950326_0715|INFO|tag|Requested_partitions|21000
2024-03-04 21:35:59,273|54262|application_1709003950326_0715|INFO|tag|Sample_size|1333781
2024-03-04 21:35:59,274|54263|application_1709003950326_0715|INFO|tag|Fraction|0.01003722781272588
2024-03-04 21:36:23,852|78841|application_1709003950326_0715|INFO|tag|Kdtree|maxItemsPerCell|63
2024-03-04 21:36:26,417|81406|application_1709003950326_0715|TIME|tag|21000|Kdtree|creation|27.140594272
2024-03-04 21:36:26,418|81407|application_1709003950326_0715|INFO|tag|21000|Kdtree|space|30523
2024-03-04 21:40:15,077|310066|application_1709003950326_0715|INFO|tag|Kdtree|21000|nEdgesA|69209173
2024-03-04 21:40:15,077|310066|application_1709003950326_0715|INFO|tag|Kdtree|21000|nEdgesB|64945654
2024-03-04 21:40:15,078|310067|application_1709003950326_0715|TIME|tag|21000|Kdtree|partitioning|228.654582418
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 29399 in stage 13.0 failed 4 times, most recent failure: Lost task 29399.3 in stage 13.0 (TID 92304, mr-10, executor 2): java.lang.NullPointerException

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.DCELOverlay2$.overlay(DCELOverlay2.scala:34)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:132)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.Utils$.timer(Utils.scala:162)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$.main(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner.main(SDCEL_Partitioner.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.NullPointerException

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 22000 --kpath /tmp/edgesCells_GADM_K_22000.wkt --qpath /tmp/edgesCells_GADM_Q_22000.wkt --master yarn
2024-03-04 21:44:40,361|14265|application_1709003950326_0716|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 22000 --kpath /tmp/edgesCells_GADM_K_22000.wkt --qpath /tmp/edgesCells_GADM_Q_22000.wkt --master yarn
2024-03-04 21:44:40,361|14265|application_1709003950326_0716|TIME|Start
2024-03-04 21:44:40,362|14266|application_1709003950326_0716|INFO|tag|scale|1000.0
2024-03-04 21:44:55,669|29573|application_1709003950326_0716|INFO|tag|edgesA|68779746
2024-03-04 21:45:09,413|43317|application_1709003950326_0716|INFO|tag|edgesB|64598411
2024-03-04 21:45:17,337|51241|application_1709003950326_0716|INFO|tag|TotalEdges|133378157
2024-03-04 21:45:26,197|60101|application_1709003950326_0716|INFO|tag|Requested_partitions|22000
2024-03-04 21:45:26,198|60102|application_1709003950326_0716|INFO|tag|Sample_size|1333781
2024-03-04 21:45:26,200|60104|application_1709003950326_0716|INFO|tag|Fraction|0.01003722781272588
2024-03-04 21:45:57,638|91542|application_1709003950326_0716|INFO|tag|Kdtree|maxItemsPerCell|60
2024-03-04 21:46:00,877|94781|application_1709003950326_0716|TIME|tag|22000|Kdtree|creation|34.675858304
2024-03-04 21:46:00,878|94782|application_1709003950326_0716|INFO|tag|22000|Kdtree|space|32095
2024-03-04 21:50:23,685|357589|application_1709003950326_0716|INFO|tag|Kdtree|22000|nEdgesA|69222864
2024-03-04 21:50:23,686|357590|application_1709003950326_0716|INFO|tag|Kdtree|22000|nEdgesB|64959464
2024-03-04 21:50:23,686|357590|application_1709003950326_0716|TIME|tag|22000|Kdtree|partitioning|262.805885055
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 8130 in stage 13.0 failed 4 times, most recent failure: Lost task 8130.3 in stage 13.0 (TID 76376, mr-09, executor 5): java.lang.NullPointerException

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.DCELOverlay2$.overlay(DCELOverlay2.scala:34)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:132)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.Utils$.timer(Utils.scala:162)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$.main(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner.main(SDCEL_Partitioner.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.NullPointerException

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 16000 --kpath /tmp/edgesCells_GADM_K_16000.wkt --qpath /tmp/edgesCells_GADM_Q_16000.wkt --master yarn
2024-03-04 21:52:26,259|13705|application_1709003950326_0717|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 16000 --kpath /tmp/edgesCells_GADM_K_16000.wkt --qpath /tmp/edgesCells_GADM_Q_16000.wkt --master yarn
2024-03-04 21:52:26,259|13705|application_1709003950326_0717|TIME|Start
2024-03-04 21:52:26,259|13705|application_1709003950326_0717|INFO|tag|scale|1000.0
2024-03-04 21:52:42,277|29723|application_1709003950326_0717|INFO|tag|edgesA|68779746
2024-03-04 21:52:52,520|39966|application_1709003950326_0717|INFO|tag|edgesB|64598411
2024-03-04 21:52:59,668|47114|application_1709003950326_0717|INFO|tag|TotalEdges|133378157
2024-03-04 21:53:01,378|48824|application_1709003950326_0717|INFO|tag|Requested_partitions|16000
2024-03-04 21:53:01,379|48825|application_1709003950326_0717|INFO|tag|Sample_size|1333781
2024-03-04 21:53:01,380|48826|application_1709003950326_0717|INFO|tag|Fraction|0.01003722781272588
2024-03-04 21:53:21,334|68780|application_1709003950326_0717|INFO|tag|Kdtree|maxItemsPerCell|83
2024-03-04 21:53:24,564|72010|application_1709003950326_0717|TIME|tag|16000|Kdtree|creation|23.182468348
2024-03-04 21:53:24,565|72011|application_1709003950326_0717|INFO|tag|16000|Kdtree|space|23127
2024-03-04 21:56:48,915|276361|application_1709003950326_0717|INFO|tag|Kdtree|16000|nEdgesA|69133552
2024-03-04 21:56:48,915|276361|application_1709003950326_0717|INFO|tag|Kdtree|16000|nEdgesB|64882865
2024-03-04 21:56:48,915|276361|application_1709003950326_0717|TIME|tag|16000|Kdtree|partitioning|204.347369084
2024-03-04 22:02:22,121|609567|application_1709003950326_0717|INFO|tag|Kdtree|16000|nOverlay|300291
2024-03-04 22:02:22,121|609567|application_1709003950326_0717|TIME|tag|16000|Kdtree|overlay|333.198021113
2024-03-04 22:02:22,763|610209|Saved /tmp/edgesCells_GADM_K_16000.wkt in 0.04s [23127 records].
2024-03-04 22:02:23,744|611190|application_1709003950326_0717|INFO|tag|Quadtree|16000|maxItemsPerCell|83
2024-03-04 22:02:31,971|619417|application_1709003950326_0717|TIME|tag|16000|Quadtree|creation|9.205498334
2024-03-04 22:02:31,971|619417|application_1709003950326_0717|INFO|tag|16000|Quadtree|space|43351
2024-03-04 22:08:17,371|964817|application_1709003950326_0717|INFO|tag|Quadtree|16000|nEdgesA|69085209
2024-03-04 22:08:17,371|964817|application_1709003950326_0717|INFO|tag|Quadtree|16000|nEdgesB|64825677
2024-03-04 22:08:17,371|964817|application_1709003950326_0717|TIME|tag|16000|Quadtree|partitioning|345.398351806
2024-03-04 22:14:52,756|1360202|application_1709003950326_0717|INFO|tag|Quadtree|16000|nOverlay|305225
2024-03-04 22:14:52,757|1360203|application_1709003950326_0717|TIME|tag|16000|Quadtree|overlay|395.379824074
2024-03-04 22:14:53,761|1361207|Saved /tmp/edgesCells_GADM_Q_16000.wkt in 0.08s [43351 records].
2024-03-04 22:14:53,955|1361401|application_1709003950326_0717|TIME|End

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 17000 --kpath /tmp/edgesCells_GADM_K_17000.wkt --qpath /tmp/edgesCells_GADM_Q_17000.wkt --master yarn
2024-03-04 22:15:15,368|14371|application_1709003950326_0718|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 17000 --kpath /tmp/edgesCells_GADM_K_17000.wkt --qpath /tmp/edgesCells_GADM_Q_17000.wkt --master yarn
2024-03-04 22:15:15,368|14371|application_1709003950326_0718|TIME|Start
2024-03-04 22:15:15,369|14372|application_1709003950326_0718|INFO|tag|scale|1000.0
2024-03-04 22:15:31,005|30008|application_1709003950326_0718|INFO|tag|edgesA|68779746
2024-03-04 22:15:41,700|40703|application_1709003950326_0718|INFO|tag|edgesB|64598411
2024-03-04 22:15:43,744|42747|application_1709003950326_0718|INFO|tag|TotalEdges|133378157
2024-03-04 22:15:58,995|57998|application_1709003950326_0718|INFO|tag|Requested_partitions|17000
2024-03-04 22:15:58,997|58000|application_1709003950326_0718|INFO|tag|Sample_size|1333781
2024-03-04 22:15:58,999|58002|application_1709003950326_0718|INFO|tag|Fraction|0.01003722781272588
2024-03-04 22:16:28,190|87193|application_1709003950326_0718|INFO|tag|Kdtree|maxItemsPerCell|78
2024-03-04 22:16:30,815|89818|application_1709003950326_0718|TIME|tag|17000|Kdtree|creation|31.814227952
2024-03-04 22:16:30,815|89818|application_1709003950326_0718|INFO|tag|17000|Kdtree|space|24630
2024-03-04 22:20:05,898|304901|application_1709003950326_0718|INFO|tag|Kdtree|17000|nEdgesA|69142692
2024-03-04 22:20:05,898|304901|application_1709003950326_0718|INFO|tag|Kdtree|17000|nEdgesB|64891466
2024-03-04 22:20:05,898|304901|application_1709003950326_0718|TIME|tag|17000|Kdtree|partitioning|215.308654374
2024-03-04 22:27:39,263|758266|application_1709003950326_0718|INFO|tag|Kdtree|17000|nOverlay|300681
2024-03-04 22:27:39,264|758267|application_1709003950326_0718|TIME|tag|17000|Kdtree|overlay|453.361415289
2024-03-04 22:27:39,991|758994|Saved /tmp/edgesCells_GADM_K_17000.wkt in 0.04s [24630 records].
2024-03-04 22:27:40,929|759932|application_1709003950326_0718|INFO|tag|Quadtree|17000|maxItemsPerCell|78
2024-03-04 22:27:48,450|767453|application_1709003950326_0718|TIME|tag|17000|Quadtree|creation|8.457706929
2024-03-04 22:27:48,451|767454|application_1709003950326_0718|INFO|tag|17000|Quadtree|space|46108
2024-03-04 22:34:06,370|1145373|application_1709003950326_0718|INFO|tag|Quadtree|17000|nEdgesA|69096110
2024-03-04 22:34:06,371|1145374|application_1709003950326_0718|INFO|tag|Quadtree|17000|nEdgesB|64833918
2024-03-04 22:34:06,371|1145374|application_1709003950326_0718|TIME|tag|17000|Quadtree|partitioning|377.918262582
2024-03-04 22:42:39,817|1658820|application_1709003950326_0718|INFO|tag|Quadtree|17000|nOverlay|306209
2024-03-04 22:42:39,817|1658820|application_1709003950326_0718|TIME|tag|17000|Quadtree|overlay|513.441755961
2024-03-04 22:42:40,950|1659953|Saved /tmp/edgesCells_GADM_Q_17000.wkt in 0.09s [46108 records].
2024-03-04 22:42:41,157|1660160|application_1709003950326_0718|TIME|End

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 18000 --kpath /tmp/edgesCells_GADM_K_18000.wkt --qpath /tmp/edgesCells_GADM_Q_18000.wkt --master yarn
2024-03-04 22:43:02,391|14268|application_1709003950326_0719|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 18000 --kpath /tmp/edgesCells_GADM_K_18000.wkt --qpath /tmp/edgesCells_GADM_Q_18000.wkt --master yarn
2024-03-04 22:43:02,392|14269|application_1709003950326_0719|TIME|Start
2024-03-04 22:43:02,392|14269|application_1709003950326_0719|INFO|tag|scale|1000.0
2024-03-04 22:43:17,631|29508|application_1709003950326_0719|INFO|tag|edgesA|68779746
2024-03-04 22:43:30,919|42796|application_1709003950326_0719|INFO|tag|edgesB|64598411
2024-03-04 22:43:37,245|49122|application_1709003950326_0719|INFO|tag|TotalEdges|133378157
2024-03-04 22:44:06,977|78854|application_1709003950326_0719|INFO|tag|Requested_partitions|18000
2024-03-04 22:44:06,979|78856|application_1709003950326_0719|INFO|tag|Sample_size|1333781
2024-03-04 22:44:06,980|78857|application_1709003950326_0719|INFO|tag|Fraction|0.01003722781272588
2024-03-04 22:44:18,894|90771|application_1709003950326_0719|INFO|tag|Kdtree|maxItemsPerCell|74
2024-03-04 22:44:21,862|93739|application_1709003950326_0719|TIME|tag|18000|Kdtree|creation|14.880528031
2024-03-04 22:44:21,863|93740|application_1709003950326_0719|INFO|tag|18000|Kdtree|space|26030
2024-03-04 22:47:55,606|307483|application_1709003950326_0719|INFO|tag|Kdtree|18000|nEdgesA|69158757
2024-03-04 22:47:55,606|307483|application_1709003950326_0719|INFO|tag|Kdtree|18000|nEdgesB|64906309
2024-03-04 22:47:55,606|307483|application_1709003950326_0719|TIME|tag|18000|Kdtree|partitioning|213.741136879
2024-03-04 22:54:01,716|673593|application_1709003950326_0719|INFO|tag|Kdtree|18000|nOverlay|301135
2024-03-04 22:54:01,716|673593|application_1709003950326_0719|TIME|tag|18000|Kdtree|overlay|366.105295293
2024-03-04 22:54:02,443|674320|Saved /tmp/edgesCells_GADM_K_18000.wkt in 0.04s [26030 records].
2024-03-04 22:54:03,245|675122|application_1709003950326_0719|INFO|tag|Quadtree|18000|maxItemsPerCell|74
2024-03-04 22:54:10,098|681975|application_1709003950326_0719|TIME|tag|18000|Quadtree|creation|7.65317344
2024-03-04 22:54:10,098|681975|application_1709003950326_0719|INFO|tag|18000|Quadtree|space|48754
2024-03-04 23:01:04,146|1096023|application_1709003950326_0719|INFO|tag|Quadtree|18000|nEdgesA|69105579
2024-03-04 23:01:04,146|1096023|application_1709003950326_0719|INFO|tag|Quadtree|18000|nEdgesB|64841390
2024-03-04 23:01:04,146|1096023|application_1709003950326_0719|TIME|tag|18000|Quadtree|partitioning|414.045290135
2024-03-04 23:09:07,466|1579343|application_1709003950326_0719|INFO|tag|Quadtree|18000|nOverlay|307196
2024-03-04 23:09:07,466|1579343|application_1709003950326_0719|TIME|tag|18000|Quadtree|overlay|483.314941852
2024-03-04 23:09:08,591|1580468|Saved /tmp/edgesCells_GADM_Q_18000.wkt in 0.08s [48754 records].
2024-03-04 23:09:08,770|1580647|application_1709003950326_0719|TIME|End

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 19000 --kpath /tmp/edgesCells_GADM_K_19000.wkt --qpath /tmp/edgesCells_GADM_Q_19000.wkt --master yarn
2024-03-04 23:09:30,067|14387|application_1709003950326_0720|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 19000 --kpath /tmp/edgesCells_GADM_K_19000.wkt --qpath /tmp/edgesCells_GADM_Q_19000.wkt --master yarn
2024-03-04 23:09:30,068|14388|application_1709003950326_0720|TIME|Start
2024-03-04 23:09:30,068|14388|application_1709003950326_0720|INFO|tag|scale|1000.0
2024-03-04 23:09:45,690|30010|application_1709003950326_0720|INFO|tag|edgesA|68779746
2024-03-04 23:09:55,688|40008|application_1709003950326_0720|INFO|tag|edgesB|64598411
2024-03-04 23:10:01,932|46252|application_1709003950326_0720|INFO|tag|TotalEdges|133378157
2024-03-04 23:10:09,949|54269|application_1709003950326_0720|INFO|tag|Requested_partitions|19000
2024-03-04 23:10:09,952|54272|application_1709003950326_0720|INFO|tag|Sample_size|1333781
2024-03-04 23:10:09,954|54274|application_1709003950326_0720|INFO|tag|Fraction|0.01003722781272588
2024-03-04 23:10:30,683|75003|application_1709003950326_0720|INFO|tag|Kdtree|maxItemsPerCell|70
2024-03-04 23:10:34,283|78603|application_1709003950326_0720|TIME|tag|19000|Kdtree|creation|24.326176014
2024-03-04 23:10:34,284|78604|application_1709003950326_0720|INFO|tag|19000|Kdtree|space|27493
2024-03-04 23:14:21,207|305527|application_1709003950326_0720|INFO|tag|Kdtree|19000|nEdgesA|69181202
2024-03-04 23:14:21,207|305527|application_1709003950326_0720|INFO|tag|Kdtree|19000|nEdgesB|64923383
2024-03-04 23:14:21,207|305527|application_1709003950326_0720|TIME|tag|19000|Kdtree|partitioning|226.91983254
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 25255 in stage 13.0 failed 4 times, most recent failure: Lost task 25255.3 in stage 13.0 (TID 80144, mr-03, executor 2): java.lang.NullPointerException

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.DCELOverlay2$.overlay(DCELOverlay2.scala:34)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:132)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.Utils$.timer(Utils.scala:162)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$.main(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner.main(SDCEL_Partitioner.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.NullPointerException

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 20000 --kpath /tmp/edgesCells_GADM_K_20000.wkt --qpath /tmp/edgesCells_GADM_Q_20000.wkt --master yarn
2024-03-04 23:18:34,011|13453|application_1709003950326_0721|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 20000 --kpath /tmp/edgesCells_GADM_K_20000.wkt --qpath /tmp/edgesCells_GADM_Q_20000.wkt --master yarn
2024-03-04 23:18:34,012|13454|application_1709003950326_0721|TIME|Start
2024-03-04 23:18:34,012|13454|application_1709003950326_0721|INFO|tag|scale|1000.0
2024-03-04 23:18:49,991|29433|application_1709003950326_0721|INFO|tag|edgesA|68779746
2024-03-04 23:18:59,450|38892|application_1709003950326_0721|INFO|tag|edgesB|64598411
2024-03-04 23:19:04,972|44414|application_1709003950326_0721|INFO|tag|TotalEdges|133378157
2024-03-04 23:19:06,608|46050|application_1709003950326_0721|INFO|tag|Requested_partitions|20000
2024-03-04 23:19:06,609|46051|application_1709003950326_0721|INFO|tag|Sample_size|1333781
2024-03-04 23:19:06,611|46053|application_1709003950326_0721|INFO|tag|Fraction|0.01003722781272588
2024-03-04 23:19:35,211|74653|application_1709003950326_0721|INFO|tag|Kdtree|maxItemsPerCell|66
2024-03-04 23:19:38,247|77689|application_1709003950326_0721|TIME|tag|20000|Kdtree|creation|31.634347501
2024-03-04 23:19:38,247|77689|application_1709003950326_0721|INFO|tag|20000|Kdtree|space|29114
2024-03-04 23:23:32,239|311681|application_1709003950326_0721|INFO|tag|Kdtree|20000|nEdgesA|69188777
2024-03-04 23:23:32,240|311682|application_1709003950326_0721|INFO|tag|Kdtree|20000|nEdgesB|64927390
2024-03-04 23:23:32,240|311682|application_1709003950326_0721|TIME|tag|20000|Kdtree|partitioning|233.9898651
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 19056 in stage 13.0 failed 4 times, most recent failure: Lost task 19056.3 in stage 13.0 (TID 80812, mr-03, executor 12): java.lang.NullPointerException
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$10.apply(LocalDCEL.scala:71)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$10.apply(LocalDCEL.scala:71)
	at scala.collection.TraversableLike$$anonfun$filterImpl$1.apply(TraversableLike.scala:248)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at scala.collection.TraversableLike$class.filterImpl(TraversableLike.scala:247)
	at scala.collection.TraversableLike$class.filter(TraversableLike.scala:259)
	at scala.collection.AbstractTraversable.filter(Traversable.scala:104)
	at edu.ucr.dblab.sdcel.LocalDCEL$.merge(LocalDCEL.scala:71)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$1.apply(LocalDCEL.scala:56)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$1.apply(LocalDCEL.scala:19)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.DCELOverlay2$.overlay(DCELOverlay2.scala:34)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:132)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.Utils$.timer(Utils.scala:162)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$.main(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner.main(SDCEL_Partitioner.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.NullPointerException
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$10.apply(LocalDCEL.scala:71)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$10.apply(LocalDCEL.scala:71)
	at scala.collection.TraversableLike$$anonfun$filterImpl$1.apply(TraversableLike.scala:248)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at scala.collection.TraversableLike$class.filterImpl(TraversableLike.scala:247)
	at scala.collection.TraversableLike$class.filter(TraversableLike.scala:259)
	at scala.collection.AbstractTraversable.filter(Traversable.scala:104)
	at edu.ucr.dblab.sdcel.LocalDCEL$.merge(LocalDCEL.scala:71)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$1.apply(LocalDCEL.scala:56)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$1.apply(LocalDCEL.scala:19)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 21000 --kpath /tmp/edgesCells_GADM_K_21000.wkt --qpath /tmp/edgesCells_GADM_Q_21000.wkt --master yarn
2024-03-04 23:27:07,094|14378|application_1709003950326_0722|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 21000 --kpath /tmp/edgesCells_GADM_K_21000.wkt --qpath /tmp/edgesCells_GADM_Q_21000.wkt --master yarn
2024-03-04 23:27:07,095|14379|application_1709003950326_0722|TIME|Start
2024-03-04 23:27:07,095|14379|application_1709003950326_0722|INFO|tag|scale|1000.0
2024-03-04 23:27:22,451|29735|application_1709003950326_0722|INFO|tag|edgesA|68779746
2024-03-04 23:27:33,398|40682|application_1709003950326_0722|INFO|tag|edgesB|64598411
2024-03-04 23:27:38,981|46265|application_1709003950326_0722|INFO|tag|TotalEdges|133378157
2024-03-04 23:27:47,768|55052|application_1709003950326_0722|INFO|tag|Requested_partitions|21000
2024-03-04 23:27:47,770|55054|application_1709003950326_0722|INFO|tag|Sample_size|1333781
2024-03-04 23:27:47,771|55055|application_1709003950326_0722|INFO|tag|Fraction|0.01003722781272588
2024-03-04 23:28:10,113|77397|application_1709003950326_0722|INFO|tag|Kdtree|maxItemsPerCell|63
2024-03-04 23:28:12,739|80023|application_1709003950326_0722|TIME|tag|21000|Kdtree|creation|24.966498612
2024-03-04 23:28:12,740|80024|application_1709003950326_0722|INFO|tag|21000|Kdtree|space|30547
2024-03-04 23:32:23,990|331274|application_1709003950326_0722|INFO|tag|Kdtree|21000|nEdgesA|69208269
2024-03-04 23:32:23,990|331274|application_1709003950326_0722|INFO|tag|Kdtree|21000|nEdgesB|64947470
2024-03-04 23:32:23,991|331275|application_1709003950326_0722|TIME|tag|21000|Kdtree|partitioning|251.248979705
2024-03-04 23:38:14,109|681393|application_1709003950326_0722|INFO|tag|Kdtree|21000|nOverlay|302456
2024-03-04 23:38:14,109|681393|application_1709003950326_0722|TIME|tag|21000|Kdtree|overlay|350.113998854
2024-03-04 23:38:14,881|682165|Saved /tmp/edgesCells_GADM_K_21000.wkt in 0.04s [30547 records].
2024-03-04 23:38:15,649|682933|application_1709003950326_0722|INFO|tag|Quadtree|21000|maxItemsPerCell|63
2024-03-04 23:38:23,310|690594|application_1709003950326_0722|TIME|tag|21000|Quadtree|creation|8.426284831
2024-03-04 23:38:23,310|690594|application_1709003950326_0722|INFO|tag|21000|Quadtree|space|57829
2024-03-04 23:46:44,238|1191522|application_1709003950326_0722|INFO|tag|Quadtree|21000|nEdgesA|69139379
2024-03-04 23:46:44,238|1191522|application_1709003950326_0722|INFO|tag|Quadtree|21000|nEdgesB|64867616
2024-03-04 23:46:44,239|1191523|application_1709003950326_0722|TIME|tag|21000|Quadtree|partitioning|500.925484317
2024-03-04 23:54:28,567|1655851|application_1709003950326_0722|INFO|tag|Quadtree|21000|nOverlay|310460
2024-03-04 23:54:28,567|1655851|application_1709003950326_0722|TIME|tag|21000|Quadtree|overlay|464.320756816
2024-03-04 23:54:29,922|1657206|Saved /tmp/edgesCells_GADM_Q_21000.wkt in 0.09s [57829 records].
2024-03-04 23:54:30,115|1657399|application_1709003950326_0722|TIME|End

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 22000 --kpath /tmp/edgesCells_GADM_K_22000.wkt --qpath /tmp/edgesCells_GADM_Q_22000.wkt --master yarn
2024-03-04 23:54:51,848|14513|application_1709003950326_0723|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 22000 --kpath /tmp/edgesCells_GADM_K_22000.wkt --qpath /tmp/edgesCells_GADM_Q_22000.wkt --master yarn
2024-03-04 23:54:51,848|14513|application_1709003950326_0723|TIME|Start
2024-03-04 23:54:51,849|14514|application_1709003950326_0723|INFO|tag|scale|1000.0
2024-03-04 23:55:07,367|30032|application_1709003950326_0723|INFO|tag|edgesA|68779746
2024-03-04 23:55:20,368|43033|application_1709003950326_0723|INFO|tag|edgesB|64598411
2024-03-04 23:55:23,813|46478|application_1709003950326_0723|INFO|tag|TotalEdges|133378157
2024-03-04 23:55:35,521|58186|application_1709003950326_0723|INFO|tag|Requested_partitions|22000
2024-03-04 23:55:35,523|58188|application_1709003950326_0723|INFO|tag|Sample_size|1333781
2024-03-04 23:55:35,526|58191|application_1709003950326_0723|INFO|tag|Fraction|0.01003722781272588
2024-03-04 23:55:58,789|81454|application_1709003950326_0723|INFO|tag|Kdtree|maxItemsPerCell|60
2024-03-04 23:56:01,482|84147|application_1709003950326_0723|TIME|tag|22000|Kdtree|creation|25.951760697
2024-03-04 23:56:01,482|84147|application_1709003950326_0723|INFO|tag|22000|Kdtree|space|32094
2024-03-05 00:00:22,073|344738|application_1709003950326_0723|INFO|tag|Kdtree|22000|nEdgesA|69224839
2024-03-05 00:00:22,074|344739|application_1709003950326_0723|INFO|tag|Kdtree|22000|nEdgesB|64960173
2024-03-05 00:00:22,075|344740|application_1709003950326_0723|TIME|tag|22000|Kdtree|partitioning|260.589488115
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 20834 in stage 13.0 failed 4 times, most recent failure: Lost task 20834.3 in stage 13.0 (TID 86791, mr-05, executor 9): java.lang.NullPointerException
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$10.apply(LocalDCEL.scala:71)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$10.apply(LocalDCEL.scala:71)
	at scala.collection.TraversableLike$$anonfun$filterImpl$1.apply(TraversableLike.scala:248)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at scala.collection.TraversableLike$class.filterImpl(TraversableLike.scala:247)
	at scala.collection.TraversableLike$class.filter(TraversableLike.scala:259)
	at scala.collection.AbstractTraversable.filter(Traversable.scala:104)
	at edu.ucr.dblab.sdcel.LocalDCEL$.merge(LocalDCEL.scala:71)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$1.apply(LocalDCEL.scala:56)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$1.apply(LocalDCEL.scala:19)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.DCELOverlay2$.overlay(DCELOverlay2.scala:34)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:132)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.Utils$.timer(Utils.scala:162)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$.main(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner.main(SDCEL_Partitioner.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.NullPointerException
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$10.apply(LocalDCEL.scala:71)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$10.apply(LocalDCEL.scala:71)
	at scala.collection.TraversableLike$$anonfun$filterImpl$1.apply(TraversableLike.scala:248)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at scala.collection.TraversableLike$class.filterImpl(TraversableLike.scala:247)
	at scala.collection.TraversableLike$class.filter(TraversableLike.scala:259)
	at scala.collection.AbstractTraversable.filter(Traversable.scala:104)
	at edu.ucr.dblab.sdcel.LocalDCEL$.merge(LocalDCEL.scala:71)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$1.apply(LocalDCEL.scala:56)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$1.apply(LocalDCEL.scala:19)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 16000 --kpath /tmp/edgesCells_GADM_K_16000.wkt --qpath /tmp/edgesCells_GADM_Q_16000.wkt --master yarn
2024-03-05 00:03:43,870|14103|application_1709003950326_0724|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 16000 --kpath /tmp/edgesCells_GADM_K_16000.wkt --qpath /tmp/edgesCells_GADM_Q_16000.wkt --master yarn
2024-03-05 00:03:43,870|14103|application_1709003950326_0724|TIME|Start
2024-03-05 00:03:43,871|14104|application_1709003950326_0724|INFO|tag|scale|1000.0
2024-03-05 00:03:59,655|29888|application_1709003950326_0724|INFO|tag|edgesA|68779746
2024-03-05 00:04:12,283|42516|application_1709003950326_0724|INFO|tag|edgesB|64598411
2024-03-05 00:04:16,114|46347|application_1709003950326_0724|INFO|tag|TotalEdges|133378157
2024-03-05 00:04:26,399|56632|application_1709003950326_0724|INFO|tag|Requested_partitions|16000
2024-03-05 00:04:26,401|56634|application_1709003950326_0724|INFO|tag|Sample_size|1333781
2024-03-05 00:04:26,402|56635|application_1709003950326_0724|INFO|tag|Fraction|0.01003722781272588
2024-03-05 00:05:07,891|98124|application_1709003950326_0724|INFO|tag|Kdtree|maxItemsPerCell|83
2024-03-05 00:05:10,488|100721|application_1709003950326_0724|TIME|tag|16000|Kdtree|creation|44.083354907
2024-03-05 00:05:10,488|100721|application_1709003950326_0724|INFO|tag|16000|Kdtree|space|23208
2024-03-05 00:08:50,913|321146|application_1709003950326_0724|INFO|tag|Kdtree|16000|nEdgesA|69135761
2024-03-05 00:08:50,914|321147|application_1709003950326_0724|INFO|tag|Kdtree|16000|nEdgesB|64886020
2024-03-05 00:08:50,914|321147|application_1709003950326_0724|TIME|tag|16000|Kdtree|partitioning|220.423722818
2024-03-05 00:14:52,752|682985|application_1709003950326_0724|INFO|tag|Kdtree|16000|nOverlay|300061
2024-03-05 00:14:52,752|682985|application_1709003950326_0724|TIME|tag|16000|Kdtree|overlay|361.833724308
2024-03-05 00:14:53,426|683659|Saved /tmp/edgesCells_GADM_K_16000.wkt in 0.04s [23208 records].
2024-03-05 00:14:54,138|684371|application_1709003950326_0724|INFO|tag|Quadtree|16000|maxItemsPerCell|83
2024-03-05 00:15:00,124|690357|application_1709003950326_0724|TIME|tag|16000|Quadtree|creation|6.69606636
2024-03-05 00:15:00,124|690357|application_1709003950326_0724|INFO|tag|16000|Quadtree|space|43351
2024-03-05 00:20:46,360|1036593|application_1709003950326_0724|INFO|tag|Quadtree|16000|nEdgesA|69085209
2024-03-05 00:20:46,360|1036593|application_1709003950326_0724|INFO|tag|Quadtree|16000|nEdgesB|64825677
2024-03-05 00:20:46,360|1036593|application_1709003950326_0724|TIME|tag|16000|Quadtree|partitioning|347.044654601
2024-03-05 00:27:42,641|1452874|application_1709003950326_0724|INFO|tag|Quadtree|16000|nOverlay|305100
2024-03-05 00:27:42,641|1452874|application_1709003950326_0724|TIME|tag|16000|Quadtree|overlay|416.27710999
2024-03-05 00:27:43,685|1453918|Saved /tmp/edgesCells_GADM_Q_16000.wkt in 0.16s [43351 records].
2024-03-05 00:27:43,864|1454097|application_1709003950326_0724|TIME|End

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 17000 --kpath /tmp/edgesCells_GADM_K_17000.wkt --qpath /tmp/edgesCells_GADM_Q_17000.wkt --master yarn
2024-03-05 00:28:04,627|13985|application_1709003950326_0725|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 17000 --kpath /tmp/edgesCells_GADM_K_17000.wkt --qpath /tmp/edgesCells_GADM_Q_17000.wkt --master yarn
2024-03-05 00:28:04,628|13986|application_1709003950326_0725|TIME|Start
2024-03-05 00:28:04,628|13986|application_1709003950326_0725|INFO|tag|scale|1000.0
2024-03-05 00:28:20,806|30164|application_1709003950326_0725|INFO|tag|edgesA|68779746
2024-03-05 00:28:33,969|43327|application_1709003950326_0725|INFO|tag|edgesB|64598411
2024-03-05 00:28:36,232|45590|application_1709003950326_0725|INFO|tag|TotalEdges|133378157
2024-03-05 00:28:40,548|49906|application_1709003950326_0725|INFO|tag|Requested_partitions|17000
2024-03-05 00:28:40,550|49908|application_1709003950326_0725|INFO|tag|Sample_size|1333781
2024-03-05 00:28:40,551|49909|application_1709003950326_0725|INFO|tag|Fraction|0.01003722781272588
2024-03-05 00:29:20,582|89940|application_1709003950326_0725|INFO|tag|Kdtree|maxItemsPerCell|78
2024-03-05 00:29:23,518|92876|application_1709003950326_0725|TIME|tag|17000|Kdtree|creation|42.965141616
2024-03-05 00:29:23,519|92877|application_1709003950326_0725|INFO|tag|17000|Kdtree|space|24663
2024-03-05 00:32:44,852|294210|application_1709003950326_0725|INFO|tag|Kdtree|17000|nEdgesA|69150966
2024-03-05 00:32:44,853|294211|application_1709003950326_0725|INFO|tag|Kdtree|17000|nEdgesB|64902417
2024-03-05 00:32:44,854|294212|application_1709003950326_0725|TIME|tag|17000|Kdtree|partitioning|201.331558555
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 15118 in stage 13.0 failed 4 times, most recent failure: Lost task 15118.3 in stage 13.0 (TID 65396, mr-05, executor 6): java.lang.NullPointerException

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.DCELOverlay2$.overlay(DCELOverlay2.scala:34)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:132)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.Utils$.timer(Utils.scala:162)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$.main(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner.main(SDCEL_Partitioner.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.NullPointerException

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 18000 --kpath /tmp/edgesCells_GADM_K_18000.wkt --qpath /tmp/edgesCells_GADM_Q_18000.wkt --master yarn
2024-03-05 00:35:50,178|14276|application_1709003950326_0726|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 18000 --kpath /tmp/edgesCells_GADM_K_18000.wkt --qpath /tmp/edgesCells_GADM_Q_18000.wkt --master yarn
2024-03-05 00:35:50,178|14276|application_1709003950326_0726|TIME|Start
2024-03-05 00:35:50,179|14277|application_1709003950326_0726|INFO|tag|scale|1000.0
2024-03-05 00:36:06,029|30127|application_1709003950326_0726|INFO|tag|edgesA|68779746
2024-03-05 00:36:15,477|39575|application_1709003950326_0726|INFO|tag|edgesB|64598411
2024-03-05 00:36:22,143|46241|application_1709003950326_0726|INFO|tag|TotalEdges|133378157
2024-03-05 00:36:30,890|54988|application_1709003950326_0726|INFO|tag|Requested_partitions|18000
2024-03-05 00:36:30,892|54990|application_1709003950326_0726|INFO|tag|Sample_size|1333781
2024-03-05 00:36:30,894|54992|application_1709003950326_0726|INFO|tag|Fraction|0.01003722781272588
2024-03-05 00:36:57,630|81728|application_1709003950326_0726|INFO|tag|Kdtree|maxItemsPerCell|74
2024-03-05 00:37:00,778|84876|application_1709003950326_0726|TIME|tag|18000|Kdtree|creation|29.881931607
2024-03-05 00:37:00,778|84876|application_1709003950326_0726|INFO|tag|18000|Kdtree|space|26054
2024-03-05 00:40:41,388|305486|application_1709003950326_0726|INFO|tag|Kdtree|18000|nEdgesA|69167050
2024-03-05 00:40:41,388|305486|application_1709003950326_0726|INFO|tag|Kdtree|18000|nEdgesB|64905896
2024-03-05 00:40:41,389|305487|application_1709003950326_0726|TIME|tag|18000|Kdtree|partitioning|220.608275066
2024-03-05 00:46:04,767|628865|application_1709003950326_0726|INFO|tag|Kdtree|18000|nOverlay|300929
2024-03-05 00:46:04,767|628865|application_1709003950326_0726|TIME|tag|18000|Kdtree|overlay|323.373803157
2024-03-05 00:46:05,500|629598|Saved /tmp/edgesCells_GADM_K_18000.wkt in 0.05s [26054 records].
2024-03-05 00:46:06,342|630440|application_1709003950326_0726|INFO|tag|Quadtree|18000|maxItemsPerCell|74
2024-03-05 00:46:14,397|638495|application_1709003950326_0726|TIME|tag|18000|Quadtree|creation|8.895473875
2024-03-05 00:46:14,398|638496|application_1709003950326_0726|INFO|tag|18000|Quadtree|space|48754
2024-03-05 00:52:46,743|1030841|application_1709003950326_0726|INFO|tag|Quadtree|18000|nEdgesA|69105579
2024-03-05 00:52:46,743|1030841|application_1709003950326_0726|INFO|tag|Quadtree|18000|nEdgesB|64841390
2024-03-05 00:52:46,743|1030841|application_1709003950326_0726|TIME|tag|18000|Quadtree|partitioning|392.34375161
2024-03-05 00:59:47,957|1452055|application_1709003950326_0726|INFO|tag|Quadtree|18000|nOverlay|307163
2024-03-05 00:59:47,957|1452055|application_1709003950326_0726|TIME|tag|18000|Quadtree|overlay|421.209870244
2024-03-05 00:59:49,025|1453123|Saved /tmp/edgesCells_GADM_Q_18000.wkt in 0.12s [48754 records].
2024-03-05 00:59:49,354|1453452|application_1709003950326_0726|TIME|End

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 19000 --kpath /tmp/edgesCells_GADM_K_19000.wkt --qpath /tmp/edgesCells_GADM_Q_19000.wkt --master yarn
2024-03-05 01:00:11,343|14780|application_1709003950326_0727|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 19000 --kpath /tmp/edgesCells_GADM_K_19000.wkt --qpath /tmp/edgesCells_GADM_Q_19000.wkt --master yarn
2024-03-05 01:00:11,343|14780|application_1709003950326_0727|TIME|Start
2024-03-05 01:00:11,343|14780|application_1709003950326_0727|INFO|tag|scale|1000.0
2024-03-05 01:00:27,549|30986|application_1709003950326_0727|INFO|tag|edgesA|68779746
2024-03-05 01:00:37,941|41378|application_1709003950326_0727|INFO|tag|edgesB|64598411
2024-03-05 01:00:45,270|48707|application_1709003950326_0727|INFO|tag|TotalEdges|133378157
2024-03-05 01:00:54,064|57501|application_1709003950326_0727|INFO|tag|Requested_partitions|19000
2024-03-05 01:00:54,066|57503|application_1709003950326_0727|INFO|tag|Sample_size|1333781
2024-03-05 01:00:54,067|57504|application_1709003950326_0727|INFO|tag|Fraction|0.01003722781272588
2024-03-05 01:01:33,130|96567|application_1709003950326_0727|INFO|tag|Kdtree|maxItemsPerCell|70
2024-03-05 01:01:36,466|99903|application_1709003950326_0727|TIME|tag|19000|Kdtree|creation|42.396564857
2024-03-05 01:01:36,466|99903|application_1709003950326_0727|INFO|tag|19000|Kdtree|space|27497
2024-03-05 01:05:16,146|319583|application_1709003950326_0727|INFO|tag|Kdtree|19000|nEdgesA|69179746
2024-03-05 01:05:16,146|319583|application_1709003950326_0727|INFO|tag|Kdtree|19000|nEdgesB|64922384
2024-03-05 01:05:16,146|319583|application_1709003950326_0727|TIME|tag|19000|Kdtree|partitioning|219.676708951
2024-03-05 01:10:32,706|636143|application_1709003950326_0727|INFO|tag|Kdtree|19000|nOverlay|301624
2024-03-05 01:10:32,706|636143|application_1709003950326_0727|TIME|tag|19000|Kdtree|overlay|316.555903179
2024-03-05 01:10:33,539|636976|Saved /tmp/edgesCells_GADM_K_19000.wkt in 0.04s [27497 records].
2024-03-05 01:10:34,303|637740|application_1709003950326_0727|INFO|tag|Quadtree|19000|maxItemsPerCell|70
2024-03-05 01:10:43,222|646659|application_1709003950326_0727|TIME|tag|19000|Quadtree|creation|9.680670521
2024-03-05 01:10:43,222|646659|application_1709003950326_0727|INFO|tag|19000|Quadtree|space|51766
2024-03-05 01:17:39,199|1062636|application_1709003950326_0727|INFO|tag|Quadtree|19000|nEdgesA|69116962
2024-03-05 01:17:39,199|1062636|application_1709003950326_0727|INFO|tag|Quadtree|19000|nEdgesB|64850369
2024-03-05 01:17:39,199|1062636|application_1709003950326_0727|TIME|tag|19000|Quadtree|partitioning|415.158377429
2024-03-05 01:25:08,119|1511556|application_1709003950326_0727|INFO|tag|Quadtree|19000|nOverlay|308108
2024-03-05 01:25:08,120|1511557|application_1709003950326_0727|TIME|tag|19000|Quadtree|overlay|448.916171156
2024-03-05 01:25:09,187|1512624|Saved /tmp/edgesCells_GADM_Q_19000.wkt in 0.10s [51766 records].
2024-03-05 01:25:09,387|1512824|application_1709003950326_0727|TIME|End

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 20000 --kpath /tmp/edgesCells_GADM_K_20000.wkt --qpath /tmp/edgesCells_GADM_Q_20000.wkt --master yarn
2024-03-05 01:25:31,028|14743|application_1709003950326_0728|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 20000 --kpath /tmp/edgesCells_GADM_K_20000.wkt --qpath /tmp/edgesCells_GADM_Q_20000.wkt --master yarn
2024-03-05 01:25:31,029|14744|application_1709003950326_0728|TIME|Start
2024-03-05 01:25:31,029|14744|application_1709003950326_0728|INFO|tag|scale|1000.0
2024-03-05 01:25:47,032|30747|application_1709003950326_0728|INFO|tag|edgesA|68779746
2024-03-05 01:25:57,924|41639|application_1709003950326_0728|INFO|tag|edgesB|64598411
2024-03-05 01:26:00,155|43870|application_1709003950326_0728|INFO|tag|TotalEdges|133378157
2024-03-05 01:26:08,996|52711|application_1709003950326_0728|INFO|tag|Requested_partitions|20000
2024-03-05 01:26:08,997|52712|application_1709003950326_0728|INFO|tag|Sample_size|1333781
2024-03-05 01:26:08,998|52713|application_1709003950326_0728|INFO|tag|Fraction|0.01003722781272588
2024-03-05 01:26:29,959|73674|application_1709003950326_0728|INFO|tag|Kdtree|maxItemsPerCell|66
2024-03-05 01:26:33,892|77607|application_1709003950326_0728|TIME|tag|20000|Kdtree|creation|24.892057026
2024-03-05 01:26:33,893|77608|application_1709003950326_0728|INFO|tag|20000|Kdtree|space|29202
2024-03-05 01:30:51,484|335199|application_1709003950326_0728|INFO|tag|Kdtree|20000|nEdgesA|69199758
2024-03-05 01:30:51,484|335199|application_1709003950326_0728|INFO|tag|Kdtree|20000|nEdgesB|64939666
2024-03-05 01:30:51,484|335199|application_1709003950326_0728|TIME|tag|20000|Kdtree|partitioning|257.588628248
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 10024 in stage 13.0 failed 4 times, most recent failure: Lost task 10024.3 in stage 13.0 (TID 68880, mr-04, executor 9): java.lang.NullPointerException

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.DCELOverlay2$.overlay(DCELOverlay2.scala:34)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:132)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.Utils$.timer(Utils.scala:162)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$.main(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner.main(SDCEL_Partitioner.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.NullPointerException

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 21000 --kpath /tmp/edgesCells_GADM_K_21000.wkt --qpath /tmp/edgesCells_GADM_Q_21000.wkt --master yarn
2024-03-05 01:32:51,500|14032|application_1709003950326_0729|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 21000 --kpath /tmp/edgesCells_GADM_K_21000.wkt --qpath /tmp/edgesCells_GADM_Q_21000.wkt --master yarn
2024-03-05 01:32:51,501|14033|application_1709003950326_0729|TIME|Start
2024-03-05 01:32:51,501|14033|application_1709003950326_0729|INFO|tag|scale|1000.0
2024-03-05 01:33:07,426|29958|application_1709003950326_0729|INFO|tag|edgesA|68779746
2024-03-05 01:33:19,064|41596|application_1709003950326_0729|INFO|tag|edgesB|64598411
2024-03-05 01:33:21,026|43558|application_1709003950326_0729|INFO|tag|TotalEdges|133378157
2024-03-05 01:33:29,354|51886|application_1709003950326_0729|INFO|tag|Requested_partitions|21000
2024-03-05 01:33:29,356|51888|application_1709003950326_0729|INFO|tag|Sample_size|1333781
2024-03-05 01:33:29,358|51890|application_1709003950326_0729|INFO|tag|Fraction|0.01003722781272588
2024-03-05 01:33:54,567|77099|application_1709003950326_0729|INFO|tag|Kdtree|maxItemsPerCell|63
2024-03-05 01:33:58,057|80589|application_1709003950326_0729|TIME|tag|21000|Kdtree|creation|28.695560878
2024-03-05 01:33:58,058|80590|application_1709003950326_0729|INFO|tag|21000|Kdtree|space|30540
2024-03-05 01:38:00,590|323122|application_1709003950326_0729|INFO|tag|Kdtree|21000|nEdgesA|69197112
2024-03-05 01:38:00,591|323123|application_1709003950326_0729|INFO|tag|Kdtree|21000|nEdgesB|64939164
2024-03-05 01:38:00,591|323123|application_1709003950326_0729|TIME|tag|21000|Kdtree|partitioning|242.529604483
2024-03-05 01:43:27,085|649617|application_1709003950326_0729|INFO|tag|Kdtree|21000|nOverlay|302184
2024-03-05 01:43:27,086|649618|application_1709003950326_0729|TIME|tag|21000|Kdtree|overlay|326.489988963
2024-03-05 01:43:28,234|650766|Saved /tmp/edgesCells_GADM_K_21000.wkt in 0.22s [30540 records].
2024-03-05 01:43:29,145|651677|application_1709003950326_0729|INFO|tag|Quadtree|21000|maxItemsPerCell|63
2024-03-05 01:43:34,346|656878|application_1709003950326_0729|TIME|tag|21000|Quadtree|creation|6.109224736
2024-03-05 01:43:34,347|656879|application_1709003950326_0729|INFO|tag|21000|Quadtree|space|57829
2024-03-05 01:51:41,691|1144223|application_1709003950326_0729|INFO|tag|Quadtree|21000|nEdgesA|69139379
2024-03-05 01:51:41,692|1144224|application_1709003950326_0729|INFO|tag|Quadtree|21000|nEdgesB|64867616
2024-03-05 01:51:41,692|1144224|application_1709003950326_0729|TIME|tag|21000|Quadtree|partitioning|487.343288361
2024-03-05 01:59:43,227|1625759|application_1709003950326_0729|INFO|tag|Quadtree|21000|nOverlay|310511
2024-03-05 01:59:43,227|1625759|application_1709003950326_0729|TIME|tag|21000|Quadtree|overlay|481.529973611
2024-03-05 01:59:44,453|1626985|Saved /tmp/edgesCells_GADM_Q_21000.wkt in 0.10s [57829 records].
2024-03-05 01:59:44,684|1627216|application_1709003950326_0729|TIME|End

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 22000 --kpath /tmp/edgesCells_GADM_K_22000.wkt --qpath /tmp/edgesCells_GADM_Q_22000.wkt --master yarn
2024-03-05 02:00:07,605|15102|application_1709003950326_0730|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 22000 --kpath /tmp/edgesCells_GADM_K_22000.wkt --qpath /tmp/edgesCells_GADM_Q_22000.wkt --master yarn
2024-03-05 02:00:07,606|15103|application_1709003950326_0730|TIME|Start
2024-03-05 02:00:07,606|15103|application_1709003950326_0730|INFO|tag|scale|1000.0
2024-03-05 02:00:23,794|31291|application_1709003950326_0730|INFO|tag|edgesA|68779746
2024-03-05 02:00:35,126|42623|application_1709003950326_0730|INFO|tag|edgesB|64598411
2024-03-05 02:00:43,267|50764|application_1709003950326_0730|INFO|tag|TotalEdges|133378157
2024-03-05 02:01:05,789|73286|application_1709003950326_0730|INFO|tag|Requested_partitions|22000
2024-03-05 02:01:05,791|73288|application_1709003950326_0730|INFO|tag|Sample_size|1333781
2024-03-05 02:01:05,792|73289|application_1709003950326_0730|INFO|tag|Fraction|0.01003722781272588
2024-03-05 02:01:34,645|102142|application_1709003950326_0730|INFO|tag|Kdtree|maxItemsPerCell|60
2024-03-05 02:01:37,889|105386|application_1709003950326_0730|TIME|tag|22000|Kdtree|creation|32.095099438
2024-03-05 02:01:37,890|105387|application_1709003950326_0730|INFO|tag|22000|Kdtree|space|32055
2024-03-05 02:05:43,690|351187|application_1709003950326_0730|INFO|tag|Kdtree|22000|nEdgesA|69224305
2024-03-05 02:05:43,691|351188|application_1709003950326_0730|INFO|tag|Kdtree|22000|nEdgesB|64958442
2024-03-05 02:05:43,691|351188|application_1709003950326_0730|TIME|tag|22000|Kdtree|partitioning|245.799399827
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 8717 in stage 13.0 failed 4 times, most recent failure: Lost task 8717.3 in stage 13.0 (TID 74802, mr-01, executor 6): java.lang.NullPointerException
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$10.apply(LocalDCEL.scala:71)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$10.apply(LocalDCEL.scala:71)
	at scala.collection.TraversableLike$$anonfun$filterImpl$1.apply(TraversableLike.scala:248)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at scala.collection.TraversableLike$class.filterImpl(TraversableLike.scala:247)
	at scala.collection.TraversableLike$class.filter(TraversableLike.scala:259)
	at scala.collection.AbstractTraversable.filter(Traversable.scala:104)
	at edu.ucr.dblab.sdcel.LocalDCEL$.merge(LocalDCEL.scala:71)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$1.apply(LocalDCEL.scala:56)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$1.apply(LocalDCEL.scala:19)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.DCELOverlay2$.overlay(DCELOverlay2.scala:34)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:132)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.Utils$.timer(Utils.scala:162)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$.main(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner.main(SDCEL_Partitioner.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.NullPointerException
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$10.apply(LocalDCEL.scala:71)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$10.apply(LocalDCEL.scala:71)
	at scala.collection.TraversableLike$$anonfun$filterImpl$1.apply(TraversableLike.scala:248)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at scala.collection.TraversableLike$class.filterImpl(TraversableLike.scala:247)
	at scala.collection.TraversableLike$class.filter(TraversableLike.scala:259)
	at scala.collection.AbstractTraversable.filter(Traversable.scala:104)
	at edu.ucr.dblab.sdcel.LocalDCEL$.merge(LocalDCEL.scala:71)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$1.apply(LocalDCEL.scala:56)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$1.apply(LocalDCEL.scala:19)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 16000 --kpath /tmp/edgesCells_GADM_K_16000.wkt --qpath /tmp/edgesCells_GADM_Q_16000.wkt --master yarn
2024-03-05 02:07:39,720|14130|application_1709003950326_0731|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 16000 --kpath /tmp/edgesCells_GADM_K_16000.wkt --qpath /tmp/edgesCells_GADM_Q_16000.wkt --master yarn
2024-03-05 02:07:39,721|14131|application_1709003950326_0731|TIME|Start
2024-03-05 02:07:39,721|14131|application_1709003950326_0731|INFO|tag|scale|1000.0
2024-03-05 02:07:54,784|29194|application_1709003950326_0731|INFO|tag|edgesA|68779746
2024-03-05 02:08:03,392|37802|application_1709003950326_0731|INFO|tag|edgesB|64598411
2024-03-05 02:08:09,374|43784|application_1709003950326_0731|INFO|tag|TotalEdges|133378157
2024-03-05 02:08:30,532|64942|application_1709003950326_0731|INFO|tag|Requested_partitions|16000
2024-03-05 02:08:30,534|64944|application_1709003950326_0731|INFO|tag|Sample_size|1333781
2024-03-05 02:08:30,535|64945|application_1709003950326_0731|INFO|tag|Fraction|0.01003722781272588
2024-03-05 02:08:40,494|74904|application_1709003950326_0731|INFO|tag|Kdtree|maxItemsPerCell|83
2024-03-05 02:08:43,215|77625|application_1709003950326_0731|TIME|tag|16000|Kdtree|creation|12.677798239
2024-03-05 02:08:43,215|77625|application_1709003950326_0731|INFO|tag|16000|Kdtree|space|23161
2024-03-05 02:12:36,577|310987|application_1709003950326_0731|INFO|tag|Kdtree|16000|nEdgesA|69132568
2024-03-05 02:12:36,577|310987|application_1709003950326_0731|INFO|tag|Kdtree|16000|nEdgesB|64883463
2024-03-05 02:12:36,578|310988|application_1709003950326_0731|TIME|tag|16000|Kdtree|partitioning|233.360580594
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 17706 in stage 13.0 failed 4 times, most recent failure: Lost task 17706.3 in stage 13.0 (TID 65190, mr-05, executor 10): java.lang.NullPointerException

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.DCELOverlay2$.overlay(DCELOverlay2.scala:34)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:132)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.Utils$.timer(Utils.scala:162)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$.main(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner.main(SDCEL_Partitioner.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.NullPointerException

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 17000 --kpath /tmp/edgesCells_GADM_K_17000.wkt --qpath /tmp/edgesCells_GADM_Q_17000.wkt --master yarn
2024-03-05 02:16:16,639|13240|application_1709003950326_0732|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 17000 --kpath /tmp/edgesCells_GADM_K_17000.wkt --qpath /tmp/edgesCells_GADM_Q_17000.wkt --master yarn
2024-03-05 02:16:16,640|13241|application_1709003950326_0732|TIME|Start
2024-03-05 02:16:16,640|13241|application_1709003950326_0732|INFO|tag|scale|1000.0
2024-03-05 02:16:32,666|29267|application_1709003950326_0732|INFO|tag|edgesA|68779746
2024-03-05 02:16:46,556|43157|application_1709003950326_0732|INFO|tag|edgesB|64598411
2024-03-05 02:16:53,399|50000|application_1709003950326_0732|INFO|tag|TotalEdges|133378157
2024-03-05 02:17:00,272|56873|application_1709003950326_0732|INFO|tag|Requested_partitions|17000
2024-03-05 02:17:00,274|56875|application_1709003950326_0732|INFO|tag|Sample_size|1333781
2024-03-05 02:17:00,275|56876|application_1709003950326_0732|INFO|tag|Fraction|0.01003722781272588
2024-03-05 02:17:32,511|89112|application_1709003950326_0732|INFO|tag|Kdtree|maxItemsPerCell|78
2024-03-05 02:17:36,071|92672|application_1709003950326_0732|TIME|tag|17000|Kdtree|creation|36.00135077
2024-03-05 02:17:36,071|92672|application_1709003950326_0732|INFO|tag|17000|Kdtree|space|24571
2024-03-05 02:21:06,482|303083|application_1709003950326_0732|INFO|tag|Kdtree|17000|nEdgesA|69147244
2024-03-05 02:21:06,482|303083|application_1709003950326_0732|INFO|tag|Kdtree|17000|nEdgesB|64895168
2024-03-05 02:21:06,482|303083|application_1709003950326_0732|TIME|tag|17000|Kdtree|partitioning|210.40785523
2024-03-05 02:26:33,796|630397|application_1709003950326_0732|INFO|tag|Kdtree|17000|nOverlay|300625
2024-03-05 02:26:33,796|630397|application_1709003950326_0732|TIME|tag|17000|Kdtree|overlay|327.308575474
2024-03-05 02:26:34,564|631165|Saved /tmp/edgesCells_GADM_K_17000.wkt in 0.04s [24571 records].
2024-03-05 02:26:35,773|632374|application_1709003950326_0732|INFO|tag|Quadtree|17000|maxItemsPerCell|78
2024-03-05 02:26:41,589|638190|application_1709003950326_0732|TIME|tag|17000|Quadtree|creation|7.019546661
2024-03-05 02:26:41,590|638191|application_1709003950326_0732|INFO|tag|17000|Quadtree|space|46108
2024-03-05 02:32:53,097|1009698|application_1709003950326_0732|INFO|tag|Quadtree|17000|nEdgesA|69096110
2024-03-05 02:32:53,097|1009698|application_1709003950326_0732|INFO|tag|Quadtree|17000|nEdgesB|64833918
2024-03-05 02:32:53,097|1009698|application_1709003950326_0732|TIME|tag|17000|Quadtree|partitioning|371.505206342
2024-03-05 02:39:47,002|1423603|application_1709003950326_0732|INFO|tag|Quadtree|17000|nOverlay|306245
2024-03-05 02:39:47,002|1423603|application_1709003950326_0732|TIME|tag|17000|Quadtree|overlay|413.90024167
2024-03-05 02:39:48,011|1424612|Saved /tmp/edgesCells_GADM_Q_17000.wkt in 0.08s [46108 records].
2024-03-05 02:39:48,218|1424819|application_1709003950326_0732|TIME|End

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 18000 --kpath /tmp/edgesCells_GADM_K_18000.wkt --qpath /tmp/edgesCells_GADM_Q_18000.wkt --master yarn
2024-03-05 02:40:08,906|14002|application_1709003950326_0733|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 18000 --kpath /tmp/edgesCells_GADM_K_18000.wkt --qpath /tmp/edgesCells_GADM_Q_18000.wkt --master yarn
2024-03-05 02:40:08,907|14003|application_1709003950326_0733|TIME|Start
2024-03-05 02:40:08,907|14003|application_1709003950326_0733|INFO|tag|scale|1000.0
2024-03-05 02:40:24,578|29674|application_1709003950326_0733|INFO|tag|edgesA|68779746
2024-03-05 02:40:35,979|41075|application_1709003950326_0733|INFO|tag|edgesB|64598411
2024-03-05 02:40:37,580|42676|application_1709003950326_0733|INFO|tag|TotalEdges|133378157
2024-03-05 02:41:01,111|66207|application_1709003950326_0733|INFO|tag|Requested_partitions|18000
2024-03-05 02:41:01,113|66209|application_1709003950326_0733|INFO|tag|Sample_size|1333781
2024-03-05 02:41:01,114|66210|application_1709003950326_0733|INFO|tag|Fraction|0.01003722781272588
2024-03-05 02:41:27,334|92430|application_1709003950326_0733|INFO|tag|Kdtree|maxItemsPerCell|74
2024-03-05 02:41:30,603|95699|application_1709003950326_0733|TIME|tag|18000|Kdtree|creation|29.485532052
2024-03-05 02:41:30,604|95700|application_1709003950326_0733|INFO|tag|18000|Kdtree|space|25976
2024-03-05 02:45:01,115|306211|application_1709003950326_0733|INFO|tag|Kdtree|18000|nEdgesA|69161607
2024-03-05 02:45:01,115|306211|application_1709003950326_0733|INFO|tag|Kdtree|18000|nEdgesB|64907271
2024-03-05 02:45:01,115|306211|application_1709003950326_0733|TIME|tag|18000|Kdtree|partitioning|210.508677892
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 22388 in stage 13.0 failed 4 times, most recent failure: Lost task 22388.3 in stage 13.0 (TID 75436, mr-08, executor 6): java.lang.NullPointerException
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$10.apply(LocalDCEL.scala:71)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$10.apply(LocalDCEL.scala:71)
	at scala.collection.TraversableLike$$anonfun$filterImpl$1.apply(TraversableLike.scala:248)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at scala.collection.TraversableLike$class.filterImpl(TraversableLike.scala:247)
	at scala.collection.TraversableLike$class.filter(TraversableLike.scala:259)
	at scala.collection.AbstractTraversable.filter(Traversable.scala:104)
	at edu.ucr.dblab.sdcel.LocalDCEL$.merge(LocalDCEL.scala:71)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$1.apply(LocalDCEL.scala:56)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$1.apply(LocalDCEL.scala:19)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.DCELOverlay2$.overlay(DCELOverlay2.scala:34)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:132)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.Utils$.timer(Utils.scala:162)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$.main(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner.main(SDCEL_Partitioner.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.NullPointerException
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$10.apply(LocalDCEL.scala:71)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$10.apply(LocalDCEL.scala:71)
	at scala.collection.TraversableLike$$anonfun$filterImpl$1.apply(TraversableLike.scala:248)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at scala.collection.TraversableLike$class.filterImpl(TraversableLike.scala:247)
	at scala.collection.TraversableLike$class.filter(TraversableLike.scala:259)
	at scala.collection.AbstractTraversable.filter(Traversable.scala:104)
	at edu.ucr.dblab.sdcel.LocalDCEL$.merge(LocalDCEL.scala:71)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$1.apply(LocalDCEL.scala:56)
	at edu.ucr.dblab.sdcel.LocalDCEL$$anonfun$1.apply(LocalDCEL.scala:19)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:853)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 19000 --kpath /tmp/edgesCells_GADM_K_19000.wkt --qpath /tmp/edgesCells_GADM_Q_19000.wkt --master yarn
2024-03-05 02:49:03,275|13861|application_1709003950326_0734|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 19000 --kpath /tmp/edgesCells_GADM_K_19000.wkt --qpath /tmp/edgesCells_GADM_Q_19000.wkt --master yarn
2024-03-05 02:49:03,276|13862|application_1709003950326_0734|TIME|Start
2024-03-05 02:49:03,276|13862|application_1709003950326_0734|INFO|tag|scale|1000.0
2024-03-05 02:49:18,695|29281|application_1709003950326_0734|INFO|tag|edgesA|68779746
2024-03-05 02:49:33,972|44558|application_1709003950326_0734|INFO|tag|edgesB|64598411
2024-03-05 02:49:35,450|46036|application_1709003950326_0734|INFO|tag|TotalEdges|133378157
2024-03-05 02:49:45,525|56111|application_1709003950326_0734|INFO|tag|Requested_partitions|19000
2024-03-05 02:49:45,526|56112|application_1709003950326_0734|INFO|tag|Sample_size|1333781
2024-03-05 02:49:45,527|56113|application_1709003950326_0734|INFO|tag|Fraction|0.01003722781272588
2024-03-05 02:50:17,282|87868|application_1709003950326_0734|INFO|tag|Kdtree|maxItemsPerCell|70
2024-03-05 02:50:20,440|91026|application_1709003950326_0734|TIME|tag|19000|Kdtree|creation|34.911015975
2024-03-05 02:50:20,441|91027|application_1709003950326_0734|INFO|tag|19000|Kdtree|space|27498
2024-03-05 02:54:05,616|316202|application_1709003950326_0734|INFO|tag|Kdtree|19000|nEdgesA|69172460
2024-03-05 02:54:05,616|316202|application_1709003950326_0734|INFO|tag|Kdtree|19000|nEdgesB|64915169
2024-03-05 02:54:05,616|316202|application_1709003950326_0734|TIME|tag|19000|Kdtree|partitioning|225.172408642
2024-03-05 03:00:31,601|702187|application_1709003950326_0734|INFO|tag|Kdtree|19000|nOverlay|301391
2024-03-05 03:00:31,601|702187|application_1709003950326_0734|TIME|tag|19000|Kdtree|overlay|385.979616261
2024-03-05 03:00:32,513|703099|Saved /tmp/edgesCells_GADM_K_19000.wkt in 0.12s [27498 records].
2024-03-05 03:00:33,657|704243|application_1709003950326_0734|INFO|tag|Quadtree|19000|maxItemsPerCell|70
2024-03-05 03:00:42,367|712953|application_1709003950326_0734|TIME|tag|19000|Quadtree|creation|9.851626951
2024-03-05 03:00:42,367|712953|application_1709003950326_0734|INFO|tag|19000|Quadtree|space|51766
2024-03-05 03:07:47,815|1138401|application_1709003950326_0734|INFO|tag|Quadtree|19000|nEdgesA|69116962
2024-03-05 03:07:47,815|1138401|application_1709003950326_0734|INFO|tag|Quadtree|19000|nEdgesB|64850369
2024-03-05 03:07:47,815|1138401|application_1709003950326_0734|TIME|tag|19000|Quadtree|partitioning|425.446067558
2024-03-05 03:16:09,608|1640194|application_1709003950326_0734|INFO|tag|Quadtree|19000|nOverlay|308180
2024-03-05 03:16:09,608|1640194|application_1709003950326_0734|TIME|tag|19000|Quadtree|overlay|501.788308794
2024-03-05 03:16:10,744|1641330|Saved /tmp/edgesCells_GADM_Q_19000.wkt in 0.08s [51766 records].
2024-03-05 03:16:11,044|1641630|application_1709003950326_0734|TIME|End

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 20000 --kpath /tmp/edgesCells_GADM_K_20000.wkt --qpath /tmp/edgesCells_GADM_Q_20000.wkt --master yarn
2024-03-05 03:16:32,291|14309|application_1709003950326_0735|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 20000 --kpath /tmp/edgesCells_GADM_K_20000.wkt --qpath /tmp/edgesCells_GADM_Q_20000.wkt --master yarn
2024-03-05 03:16:32,292|14310|application_1709003950326_0735|TIME|Start
2024-03-05 03:16:32,292|14310|application_1709003950326_0735|INFO|tag|scale|1000.0
2024-03-05 03:16:47,786|29804|application_1709003950326_0735|INFO|tag|edgesA|68779746
2024-03-05 03:16:56,853|38871|application_1709003950326_0735|INFO|tag|edgesB|64598411
2024-03-05 03:17:01,995|44013|application_1709003950326_0735|INFO|tag|TotalEdges|133378157
2024-03-05 03:17:08,912|50930|application_1709003950326_0735|INFO|tag|Requested_partitions|20000
2024-03-05 03:17:08,914|50932|application_1709003950326_0735|INFO|tag|Sample_size|1333781
2024-03-05 03:17:08,915|50933|application_1709003950326_0735|INFO|tag|Fraction|0.01003722781272588
2024-03-05 03:17:41,121|83139|application_1709003950326_0735|INFO|tag|Kdtree|maxItemsPerCell|66
2024-03-05 03:17:43,954|85972|application_1709003950326_0735|TIME|tag|20000|Kdtree|creation|35.036825029
2024-03-05 03:17:43,954|85972|application_1709003950326_0735|INFO|tag|20000|Kdtree|space|29163
2024-03-05 03:21:52,605|334623|application_1709003950326_0735|INFO|tag|Kdtree|20000|nEdgesA|69195838
2024-03-05 03:21:52,605|334623|application_1709003950326_0735|INFO|tag|Kdtree|20000|nEdgesB|64932600
2024-03-05 03:21:52,606|334624|application_1709003950326_0735|TIME|tag|20000|Kdtree|partitioning|248.649535279
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 28128 in stage 13.0 failed 4 times, most recent failure: Lost task 28128.3 in stage 13.0 (TID 85552, mr-04, executor 12): java.lang.NullPointerException

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.DCELOverlay2$.overlay(DCELOverlay2.scala:34)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:132)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.Utils$.timer(Utils.scala:162)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$.main(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner.main(SDCEL_Partitioner.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.NullPointerException

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 21000 --kpath /tmp/edgesCells_GADM_K_21000.wkt --qpath /tmp/edgesCells_GADM_Q_21000.wkt --master yarn
2024-03-05 03:26:06,911|14252|application_1709003950326_0736|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 21000 --kpath /tmp/edgesCells_GADM_K_21000.wkt --qpath /tmp/edgesCells_GADM_Q_21000.wkt --master yarn
2024-03-05 03:26:06,911|14252|application_1709003950326_0736|TIME|Start
2024-03-05 03:26:06,911|14252|application_1709003950326_0736|INFO|tag|scale|1000.0
2024-03-05 03:26:23,351|30692|application_1709003950326_0736|INFO|tag|edgesA|68779746
2024-03-05 03:26:36,780|44121|application_1709003950326_0736|INFO|tag|edgesB|64598411
2024-03-05 03:26:44,115|51456|application_1709003950326_0736|INFO|tag|TotalEdges|133378157
2024-03-05 03:26:45,487|52828|application_1709003950326_0736|INFO|tag|Requested_partitions|21000
2024-03-05 03:26:45,489|52830|application_1709003950326_0736|INFO|tag|Sample_size|1333781
2024-03-05 03:26:45,490|52831|application_1709003950326_0736|INFO|tag|Fraction|0.01003722781272588
2024-03-05 03:27:23,179|90520|application_1709003950326_0736|INFO|tag|Kdtree|maxItemsPerCell|63
2024-03-05 03:27:26,321|93662|application_1709003950326_0736|TIME|tag|21000|Kdtree|creation|40.829447281
2024-03-05 03:27:26,322|93663|application_1709003950326_0736|INFO|tag|21000|Kdtree|space|30474
2024-03-05 03:31:26,844|334185|application_1709003950326_0736|INFO|tag|Kdtree|21000|nEdgesA|69204040
2024-03-05 03:31:26,844|334185|application_1709003950326_0736|INFO|tag|Kdtree|21000|nEdgesB|64942050
2024-03-05 03:31:26,845|334186|application_1709003950326_0736|TIME|tag|21000|Kdtree|partitioning|240.519487273
2024-03-05 03:36:44,953|652294|application_1709003950326_0736|INFO|tag|Kdtree|21000|nOverlay|302941
2024-03-05 03:36:44,954|652295|application_1709003950326_0736|TIME|tag|21000|Kdtree|overlay|318.104273728
2024-03-05 03:36:45,757|653098|Saved /tmp/edgesCells_GADM_K_21000.wkt in 0.05s [30474 records].
2024-03-05 03:36:46,605|653946|application_1709003950326_0736|INFO|tag|Quadtree|21000|maxItemsPerCell|63
2024-03-05 03:36:51,405|658746|application_1709003950326_0736|TIME|tag|21000|Quadtree|creation|5.645800306
2024-03-05 03:36:51,405|658746|application_1709003950326_0736|INFO|tag|21000|Quadtree|space|57829
2024-03-05 03:45:11,591|1158932|application_1709003950326_0736|INFO|tag|Quadtree|21000|nEdgesA|69139379
2024-03-05 03:45:11,591|1158932|application_1709003950326_0736|INFO|tag|Quadtree|21000|nEdgesB|64867616
2024-03-05 03:45:11,591|1158932|application_1709003950326_0736|TIME|tag|21000|Quadtree|partitioning|500.184154248
2024-03-05 03:53:02,009|1629350|application_1709003950326_0736|INFO|tag|Quadtree|21000|nOverlay|310635
2024-03-05 03:53:02,010|1629351|application_1709003950326_0736|TIME|tag|21000|Quadtree|overlay|470.413620627
2024-03-05 03:53:03,185|1630526|Saved /tmp/edgesCells_GADM_Q_21000.wkt in 0.09s [57829 records].
2024-03-05 03:53:03,445|1630786|application_1709003950326_0736|TIME|End

	bash bash/sdcel_partitioner_spark --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 22000 --kpath /tmp/edgesCells_GADM_K_22000.wkt --qpath /tmp/edgesCells_GADM_Q_22000.wkt --master yarn
2024-03-05 03:53:25,073|14550|application_1709003950326_0737|COMMAND|org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.kryoserializer.buffer.max=256m --conf spark.driver.memory=35g --conf spark.driver.maxResultSize=4G --conf spark.locality.wait=3s --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/acald013/Spark/2.4/conf/log4j.properties --class edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner --files /home/acald013/Spark/2.4/conf/log4j.properties --num-executors 12 --executor-cores 9 --executor-memory 20g --jars /home/acald013/.ivy2/cache/org.datasyslab/JTSplus/jars/JTSplus-0.1.4.jar,/home/acald013/.ivy2/cache/org.jgrapht/jgrapht-core/jars/jgrapht-core-1.4.0.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-api/jars/slf4j-api-1.7.26.jar,/home/acald013/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.7.25.jar,/home/acald013/.ivy2/cache/org.rogach/scallop_2.11/jars/scallop_2.11-2.1.3.jar,/home/acald013/.ivy2/cache/org.scalactic/scalactic_2.11/bundles/scalactic_2.11-3.2.12.jar,/home/acald013/.ivy2/cache/com.google.guava/guava/bundles/guava-31.1-jre.jar,/home/acald013/.ivy2/cache/com.google.guava/failureaccess/bundles/failureaccess-1.0.1.jar,/home/acald013/.ivy2/cache/com.google.guava/listenablefuture/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar,/home/acald013/.ivy2/cache/org.glassfish.jersey.bundles.repackaged/jersey-guava/bundles/jersey-guava-2.22.2.jar,/home/acald013/RIDIR/Code/SDCEL/lib/geospark-1.2.0.jar /home/acald013/RIDIR/Code/SDCEL/target/scala-2.11/sdcel_2.11-0.1.0.jar --input1 gadm/kdtree/A --input2 gadm/kdtree/B --partitions 22000 --kpath /tmp/edgesCells_GADM_K_22000.wkt --qpath /tmp/edgesCells_GADM_Q_22000.wkt --master yarn
2024-03-05 03:53:25,074|14551|application_1709003950326_0737|TIME|Start
2024-03-05 03:53:25,074|14551|application_1709003950326_0737|INFO|tag|scale|1000.0
2024-03-05 03:53:40,934|30411|application_1709003950326_0737|INFO|tag|edgesA|68779746
2024-03-05 03:53:52,411|41888|application_1709003950326_0737|INFO|tag|edgesB|64598411
2024-03-05 03:53:53,982|43459|application_1709003950326_0737|INFO|tag|TotalEdges|133378157
2024-03-05 03:54:02,469|51946|application_1709003950326_0737|INFO|tag|Requested_partitions|22000
2024-03-05 03:54:02,471|51948|application_1709003950326_0737|INFO|tag|Sample_size|1333781
2024-03-05 03:54:02,472|51949|application_1709003950326_0737|INFO|tag|Fraction|0.01003722781272588
2024-03-05 03:54:14,346|63823|application_1709003950326_0737|INFO|tag|Kdtree|maxItemsPerCell|60
2024-03-05 03:54:17,468|66945|application_1709003950326_0737|TIME|tag|22000|Kdtree|creation|14.99451236
2024-03-05 03:54:17,468|66945|application_1709003950326_0737|INFO|tag|22000|Kdtree|space|32073
2024-03-05 03:58:10,508|299985|application_1709003950326_0737|INFO|tag|Kdtree|22000|nEdgesA|69223974
2024-03-05 03:58:10,508|299985|application_1709003950326_0737|INFO|tag|Kdtree|22000|nEdgesB|64961776
2024-03-05 03:58:10,508|299985|application_1709003950326_0737|TIME|tag|22000|Kdtree|partitioning|233.038283908
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 30415 in stage 13.0 failed 4 times, most recent failure: Lost task 30415.3 in stage 13.0 (TID 95735, mr-06, executor 5): java.lang.NullPointerException

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
	at edu.ucr.dblab.sdcel.DCELOverlay2$.overlay(DCELOverlay2.scala:34)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:132)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$$anonfun$10.apply(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.Utils$.timer(Utils.scala:162)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner$.main(SDCEL_Partitioner.scala:120)
	at edu.ucr.dblab.sdcel.extension.SDCEL_Partitioner.main(SDCEL_Partitioner.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:904)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:198)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:228)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:137)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.NullPointerException
